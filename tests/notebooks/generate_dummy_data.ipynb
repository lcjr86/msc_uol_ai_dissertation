{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Dummy Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "import datetime as DT\n",
    "import datetime\n",
    "from configparser import ConfigParser\n",
    "\n",
    "import talib\n",
    "import talib as tb\n",
    "\n",
    "import mplfinance as mpf\n",
    "\n",
    "from src import utils as u\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../../data_prep/config_files/config_candlestick_patterns.ini']\n"
     ]
    }
   ],
   "source": [
    "configur = ConfigParser()\n",
    "print (configur.read('../../data_prep/config_files/config_candlestick_patterns.ini'))\n",
    "#print (\"Sections : \", configur.sections())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_ticket = \"DMYUSDT\"\n",
    "timestamp = \"1m\"\n",
    "start_date = \"1 Jan, 2017\"\n",
    "end_date = \"31 Dec, 2022\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_open = mdates.num2date(mdates.drange(DT.datetime(2016, 12, 31, 23, 45),\n",
    "                                      DT.datetime(2022, 12, 31, 23, 45),\n",
    "                                      DT.timedelta(minutes=1)))\n",
    "\n",
    "dates_close = mdates.num2date(mdates.drange(DT.datetime(2017, 1, 1),\n",
    "                                      DT.datetime(2023, 1, 1),\n",
    "                                      DT.timedelta(minutes=1)))                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 20*np.pi, len(dates_close))\n",
    "y1 = np.cos(2*x) + 3\n",
    "y2 = np.cos(x/2) + 3\n",
    "y3 = np.sin(3*x) + 3\n",
    "y4 = np.sin(x/3) + 3\n",
    "\n",
    "y1_l = np.cos(2*x) + 2\n",
    "y2_l = np.cos(x/2) + 2\n",
    "y3_l = np.sin(2*x) + 2\n",
    "y4_l = np.sin(x/2) + 2\n",
    "\n",
    "y1_h = np.cos(2*x) + 5\n",
    "y2_h = np.cos(x/2) + 5\n",
    "y3_h = np.sin(3*x) + 5\n",
    "y4_h = np.sin(x/3) + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "open = y1+y2+y3+y4\n",
    "temp = open.tolist()\n",
    "close = temp[1:]\n",
    "close.insert(len(close), temp[-1] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy = pd.DataFrame()\n",
    "df_dummy['open_time'] = dates_open\n",
    "df_dummy['open'] = open\n",
    "df_dummy['high'] = y1_h+y2_h+y3_h+y4_h\n",
    "df_dummy['low'] = y1_l+y2_l+y3_l+y4_l\n",
    "df_dummy['close'] = close\n",
    "df_dummy['volume'] = 0\n",
    "df_dummy['close_time'] = dates_close\n",
    "df_dummy['quote_asset_volume'] = 0\n",
    "df_dummy['number_of_trades'] = 0\n",
    "df_dummy['taker_buy_base_asset_volume'] = 0\n",
    "df_dummy['taker_buy_quote_asset_volume'] = 0\n",
    "df_dummy['ignore'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open_time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>close_time</th>\n",
       "      <th>quote_asset_volume</th>\n",
       "      <th>number_of_trades</th>\n",
       "      <th>taker_buy_base_asset_volume</th>\n",
       "      <th>taker_buy_quote_asset_volume</th>\n",
       "      <th>ignore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-12-31 23:45:00+00:00</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>14.000066</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01 00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-12-31 23:46:00+00:00</td>\n",
       "      <td>14.000066</td>\n",
       "      <td>22.000066</td>\n",
       "      <td>10.000050</td>\n",
       "      <td>14.000133</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01 00:01:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-12-31 23:47:00+00:00</td>\n",
       "      <td>14.000133</td>\n",
       "      <td>22.000133</td>\n",
       "      <td>10.000100</td>\n",
       "      <td>14.000199</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01 00:02:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-12-31 23:48:00+00:00</td>\n",
       "      <td>14.000199</td>\n",
       "      <td>22.000199</td>\n",
       "      <td>10.000149</td>\n",
       "      <td>14.000266</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01 00:03:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-12-31 23:49:00+00:00</td>\n",
       "      <td>14.000266</td>\n",
       "      <td>22.000266</td>\n",
       "      <td>10.000199</td>\n",
       "      <td>14.000332</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01 00:04:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3155035</th>\n",
       "      <td>2022-12-31 23:40:00+00:00</td>\n",
       "      <td>14.865800</td>\n",
       "      <td>22.865800</td>\n",
       "      <td>9.999801</td>\n",
       "      <td>14.865856</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-31 23:55:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3155036</th>\n",
       "      <td>2022-12-31 23:41:00+00:00</td>\n",
       "      <td>14.865856</td>\n",
       "      <td>22.865856</td>\n",
       "      <td>9.999851</td>\n",
       "      <td>14.865913</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-31 23:56:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3155037</th>\n",
       "      <td>2022-12-31 23:42:00+00:00</td>\n",
       "      <td>14.865913</td>\n",
       "      <td>22.865913</td>\n",
       "      <td>9.999900</td>\n",
       "      <td>14.865969</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-31 23:57:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3155038</th>\n",
       "      <td>2022-12-31 23:43:00+00:00</td>\n",
       "      <td>14.865969</td>\n",
       "      <td>22.865969</td>\n",
       "      <td>9.999950</td>\n",
       "      <td>14.866025</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-31 23:58:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3155039</th>\n",
       "      <td>2022-12-31 23:44:00+00:00</td>\n",
       "      <td>14.866025</td>\n",
       "      <td>22.866025</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>15.866025</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-31 23:59:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3155040 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        open_time       open       high        low      close  \\\n",
       "0       2016-12-31 23:45:00+00:00  14.000000  22.000000  10.000000  14.000066   \n",
       "1       2016-12-31 23:46:00+00:00  14.000066  22.000066  10.000050  14.000133   \n",
       "2       2016-12-31 23:47:00+00:00  14.000133  22.000133  10.000100  14.000199   \n",
       "3       2016-12-31 23:48:00+00:00  14.000199  22.000199  10.000149  14.000266   \n",
       "4       2016-12-31 23:49:00+00:00  14.000266  22.000266  10.000199  14.000332   \n",
       "...                           ...        ...        ...        ...        ...   \n",
       "3155035 2022-12-31 23:40:00+00:00  14.865800  22.865800   9.999801  14.865856   \n",
       "3155036 2022-12-31 23:41:00+00:00  14.865856  22.865856   9.999851  14.865913   \n",
       "3155037 2022-12-31 23:42:00+00:00  14.865913  22.865913   9.999900  14.865969   \n",
       "3155038 2022-12-31 23:43:00+00:00  14.865969  22.865969   9.999950  14.866025   \n",
       "3155039 2022-12-31 23:44:00+00:00  14.866025  22.866025  10.000000  15.866025   \n",
       "\n",
       "         volume                close_time  quote_asset_volume  \\\n",
       "0             0 2017-01-01 00:00:00+00:00                   0   \n",
       "1             0 2017-01-01 00:01:00+00:00                   0   \n",
       "2             0 2017-01-01 00:02:00+00:00                   0   \n",
       "3             0 2017-01-01 00:03:00+00:00                   0   \n",
       "4             0 2017-01-01 00:04:00+00:00                   0   \n",
       "...         ...                       ...                 ...   \n",
       "3155035       0 2022-12-31 23:55:00+00:00                   0   \n",
       "3155036       0 2022-12-31 23:56:00+00:00                   0   \n",
       "3155037       0 2022-12-31 23:57:00+00:00                   0   \n",
       "3155038       0 2022-12-31 23:58:00+00:00                   0   \n",
       "3155039       0 2022-12-31 23:59:00+00:00                   0   \n",
       "\n",
       "         number_of_trades  taker_buy_base_asset_volume  \\\n",
       "0                       0                            0   \n",
       "1                       0                            0   \n",
       "2                       0                            0   \n",
       "3                       0                            0   \n",
       "4                       0                            0   \n",
       "...                   ...                          ...   \n",
       "3155035                 0                            0   \n",
       "3155036                 0                            0   \n",
       "3155037                 0                            0   \n",
       "3155038                 0                            0   \n",
       "3155039                 0                            0   \n",
       "\n",
       "         taker_buy_quote_asset_volume  ignore  \n",
       "0                                   0       0  \n",
       "1                                   0       0  \n",
       "2                                   0       0  \n",
       "3                                   0       0  \n",
       "4                                   0       0  \n",
       "...                               ...     ...  \n",
       "3155035                             0       0  \n",
       "3155036                             0       0  \n",
       "3155037                             0       0  \n",
       "3155038                             0       0  \n",
       "3155039                             0       0  \n",
       "\n",
       "[3155040 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(name='close price', x=df_dummy['close_time'], y=df_dummy['close'], mode='lines', marker_color='#969696'))\n",
    "fig.add_trace(go.Scatter(name='high price', x=df_dummy['close_time'], y=df_dummy['high'], mode='lines', marker_color='#DBAC12'))\n",
    "fig.add_trace(go.Scatter(name='low price', x=df_dummy['close_time'], y=df_dummy['low'], mode='lines', marker_color='#12DB63'))\n",
    "fig.add_trace(go.Scatter(name='open price', x=df_dummy['close_time'], y=df_dummy['open'], mode='lines', marker_color='#990099'))\n",
    "fig.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add formatted open/close time & date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy['formatted_open_time'] = pd.to_datetime(df_dummy['open_time'], infer_datetime_format=True, unit=\"ms\")\n",
    "df_dummy['formatted_close_time'] = pd.to_datetime(df_dummy['close_time'], infer_datetime_format=True, unit=\"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy['date'] = pd.to_datetime(df_dummy['formatted_close_time']) + pd.to_timedelta(1, unit='s')\n",
    "df_dummy['date'] = pd.to_datetime(df_dummy['date']).dt.strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy['date_index'] = df_dummy['date']\n",
    "df_dummy.set_index('date_index', inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add CURL values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_curl_values(df):\n",
    "    try:\n",
    "        results_upper_shadow = []\n",
    "        results_lower_shadow = []\n",
    "        results_real_body = []\n",
    "        for index, row in df.iterrows():\n",
    "            if row.open > row.close:\n",
    "                results_upper_shadow.append(row.high - row.open)\n",
    "                results_lower_shadow.append(row.close - row.low)\n",
    "                results_real_body.append(row.open - row.close)\n",
    "            else:\n",
    "                results_upper_shadow.append(row.high - row.close)\n",
    "                results_lower_shadow.append(row.open - row.low)\n",
    "                results_real_body.append(row.close - row.open)\n",
    "\n",
    "        df['upper_shadow'] = results_upper_shadow\n",
    "        df['lower_shadow'] = results_lower_shadow\n",
    "        df['real_body'] = results_real_body\n",
    "\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(row.formatted_open_time)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy = create_curl_values(df_dummy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the candlestick values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candle_names = [\n",
    "    'CDLINVERTEDHAMMER',\n",
    "    'CDLHAMMER',\n",
    "    'CDLPIERCING',\n",
    "    'CDLMORNINGSTAR',\n",
    "    'CDLSHOOTINGSTAR',\n",
    "    'CDLHANGINGMAN',\n",
    "    'CDLDARKCLOUDCOVER',\n",
    "    'CDLEVENINGSTAR',\n",
    "    'CDLENGULFING'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract OHLC \n",
    "op = df_dummy['open']\n",
    "hi = df_dummy['high']\n",
    "lo = df_dummy['low']\n",
    "cl = df_dummy['close']\n",
    "\n",
    "# create columns for each pattern\n",
    "for candle in candle_names:\n",
    "    # below is same as;\n",
    "    # df[\"CDL3LINESTRIKE\"] = talib.CDL3LINESTRIKE(op, hi, lo, cl)\n",
    "    df_dummy[candle] = getattr(talib, candle)(op, hi, lo, cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_open_time_bullish_engulfing = df_dummy[df_dummy['CDLENGULFING']==100]['date'].to_list()\n",
    "list_open_time_bearish_engulfing = df_dummy[df_dummy['CDLENGULFING']==-100]['date'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy['CDLENGULFINGBULLISH'] = np.where(df_dummy['date'].isin(list_open_time_bullish_engulfing), 100, 0)\n",
    "df_dummy['CDLENGULFINGBEARISH'] = np.where(df_dummy['date'].isin(list_open_time_bearish_engulfing), -100, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = configur.getint('candlestick_patterns', 'window_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = ['CDLINVERTEDHAMMER', 'CDLHAMMER',\n",
    "       'CDLPIERCING', 'CDLMORNINGSTAR', 'CDLSHOOTINGSTAR', 'CDLHANGINGMAN',\n",
    "       'CDLDARKCLOUDCOVER', 'CDLEVENINGSTAR', 'CDLENGULFING',\n",
    "       'CDLENGULFINGBULLISH', 'CDLENGULFINGBEARISH']\n",
    "\n",
    "df_dummy.loc[:window_size, subset] = df_dummy.loc[:window_size, subset].replace([100, -100],[0, 0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate candlesticks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = configur.getint('candlestick_patterns', 'window_size')\n",
    "slope_size = configur.getint('candlestick_patterns', 'slope_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dates_invertedhammer = df_dummy[df_dummy['CDLINVERTEDHAMMER'] == 100]['date'].to_list()\n",
    "list_dates_hammer = df_dummy[df_dummy['CDLHAMMER'] == 100]['date'].to_list()\n",
    "list_dates_piercing = df_dummy[df_dummy['CDLPIERCING'] == 100]['date'].to_list()\n",
    "list_dates_morningstar = df_dummy[df_dummy['CDLMORNINGSTAR'] == 100]['date'].to_list()\n",
    "list_dates_bullishengulfing = df_dummy[df_dummy['CDLENGULFINGBULLISH'] == 100]['date'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_all_dates = df_dummy['date'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_validate_dates_invertedhammer = []\n",
    "list_new_sign_invertedhammer = []\n",
    "list_sign_invertedhammer = [0] * len(list_all_dates)\n",
    "for date in list_dates_invertedhammer:\n",
    "    i = u.check_intensity_trend(df_dummy, date, window_size, slope_size)\n",
    "    if(i >= 0):\n",
    "        list_validate_dates_invertedhammer.append(date)\n",
    "        list_new_sign_invertedhammer.append(i*100)\n",
    "        list_sign_invertedhammer[list_all_dates.index(date)] = i*100\n",
    "    # else:\n",
    "    #     list_sign_invertedhammer.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_validate_dates_hammer = []\n",
    "list_new_sign_hammer = []\n",
    "list_sign_hammer = [0] * len(list_all_dates)\n",
    "for date in list_dates_hammer:\n",
    "    i = u.check_intensity_trend(df_dummy, date, window_size, slope_size)\n",
    "    if(i >= 0):    \n",
    "        list_validate_dates_hammer.append(date)\n",
    "        list_new_sign_hammer.append(i*100)\n",
    "        list_sign_hammer[list_all_dates.index(date)] = i*100\n",
    "    # else:\n",
    "    #     list_sign_hammer.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_validate_dates_piercing = []\n",
    "list_new_sign_piercing = []\n",
    "list_sign_piercing = [0] * len(list_all_dates)\n",
    "for date in list_dates_piercing:\n",
    "    i = u.check_intensity_trend(df_dummy, date, window_size, slope_size)\n",
    "    if(i >= 0):\n",
    "        list_validate_dates_piercing.append(date)\n",
    "        list_new_sign_piercing.append(i*100)\n",
    "        list_sign_piercing[list_all_dates.index(date)] = i*100\n",
    "    # else:\n",
    "    #     list_sign_piercing.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_validate_dates_morningstar = []\n",
    "list_new_sign_morningstar = []\n",
    "list_sign_morningstar = [0] * len(list_all_dates)\n",
    "for date in list_dates_morningstar:\n",
    "    i = u.check_intensity_trend(df_dummy, date, window_size, slope_size)\n",
    "    if(i >= 0):\n",
    "        list_validate_dates_morningstar.append(date)\n",
    "        list_new_sign_morningstar.append(i*100)\n",
    "        list_sign_morningstar[list_all_dates.index(date)] = i*100\n",
    "    # else:\n",
    "    #     list_sign_morningstar.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_validate_dates_bullishengulfing = []\n",
    "list_new_sign_bullishengulfing = []\n",
    "list_sign_bullishengulfing = [0] * len(list_all_dates)\n",
    "for date in list_dates_bullishengulfing:\n",
    "    i = u.check_intensity_trend(df_dummy, date, window_size, slope_size)\n",
    "    # print(f'date:{date}|i:{i}')\n",
    "    if(i >= 0):\n",
    "        list_validate_dates_bullishengulfing.append(date)\n",
    "        list_new_sign_bullishengulfing.append(i*100)\n",
    "        list_sign_bullishengulfing[list_all_dates.index(date)] = i*100\n",
    "    # else:\n",
    "    #     list_new_sign_bullishengulfing.append(0)\n",
    "    #     list_sign_bullishengulfing.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dates_shootingstar = df_dummy[df_dummy['CDLSHOOTINGSTAR'] == -100]['date'].to_list()\n",
    "list_dates_hangingman = df_dummy[df_dummy['CDLHANGINGMAN'] == -100]['date'].to_list()\n",
    "list_dates_darkcloudcover = df[df['CDLDARKCLOUDCOVER'] == -100]['date'].to_list()\n",
    "list_dates_eveningstar = df_dummy[df_dummy['CDLEVENINGSTAR'] == -100]['date'].to_list()\n",
    "list_dates_bearishengulfing = df_dummy[df_dummy['CDLENGULFINGBEARISH'] == -100]['date'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_validate_dates_shootingstar = []\n",
    "list_new_sign_shootingstar = []\n",
    "list_sign_shootingstar = [0] * len(list_all_dates)\n",
    "for date in list_dates_shootingstar:\n",
    "    i = u.check_intensity_trend(df, date, window_size, slope_size)\n",
    "    if (i<=0):\n",
    "        list_validate_dates_shootingstar.append(date)\n",
    "        list_new_sign_shootingstar.append(i*100)\n",
    "        list_sign_shootingstar[list_all_dates.index(date)] = i*100\n",
    "    # else:\n",
    "    #     list_sign_shootingstar.append(0)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_validate_dates_hangingman = []\n",
    "list_new_sign_hangingman = []\n",
    "list_sign_hangingman = [0] * len(list_all_dates)\n",
    "for date in list_dates_hangingman:\n",
    "    i = u.check_intensity_trend(df, date, window_size, slope_size)\n",
    "    if (i<=0):\n",
    "        list_validate_dates_hangingman.append(date)\n",
    "        list_new_sign_hangingman.append(i*100)\n",
    "        list_sign_hangingman[list_all_dates.index(date)] = i*100\n",
    "    # else:\n",
    "    #     list_sign_hangingman.append(0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_validate_dates_darkcloudcover = []\n",
    "list_new_sign_darkcloudcover = []\n",
    "list_sign_darkcloudcover = [0] * len(list_all_dates)\n",
    "for date in list_dates_darkcloudcover:\n",
    "    i = u.check_intensity_trend(df, date, window_size, slope_size)\n",
    "    if (i<=0):\n",
    "        list_validate_dates_darkcloudcover.append(date)\n",
    "        list_new_sign_darkcloudcover.append(i*100)\n",
    "        list_sign_darkcloudcover[list_all_dates.index(date)] = i*100   \n",
    "    # else:\n",
    "    #     list_sign_darkcloudcover.append(0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_validate_dates_eveningstar = []\n",
    "list_new_sign_eveningstar = []\n",
    "list_sign_eveningstar = [0] * len(list_all_dates)\n",
    "for date in list_dates_eveningstar:\n",
    "    i = u.check_intensity_trend(df, date, window_size, slope_size)\n",
    "    if (i<=0):\n",
    "        list_validate_dates_eveningstar.append(date)\n",
    "        list_new_sign_eveningstar.append(i*100)\n",
    "        list_sign_eveningstar[list_all_dates.index(date)] = i*100\n",
    "    # else:\n",
    "    #     list_sign_eveningstar.append(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_validate_dates_bearishengulfing = []\n",
    "list_new_sign_bearishengulfing = []\n",
    "list_sign_bearishengulfing = [0] * len(list_all_dates)\n",
    "for date in list_dates_bearishengulfing:\n",
    "    i = u.check_intensity_trend(df, date, window_size, slope_size)\n",
    "    if (i<=0):\n",
    "        list_validate_dates_bearishengulfing.append(date)\n",
    "        list_new_sign_bearishengulfing.append(i*100)\n",
    "        list_sign_bearishengulfing[list_all_dates.index(date)] = i*100\n",
    "    # else:\n",
    "    #     list_sign_bearishengulfing.append(0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_new_column_name = ['CDLINVERTEDHAMMER_NEW', 'CDLHAMMER_NEW', 'CDLPIERCING_NEW', 'CDLMORNINGSTAR_NEW', 'CDLSHOOTINGSTAR_NEW', 'CDLHANGINGMAN_NEW', 'CDLDARKCLOUDCOVER_NEW', 'CDLEVENINGSTAR_NEW']\n",
    "# list_of_list_valid_dates = [list_validate_dates_invertedhammer, list_validate_dates_hammer, list_validate_dates_piercing, list_validate_dates_morningstar, list_validate_dates_shootingstar, list_validate_dates_hangingman, list_validate_dates_darkcloudcover, list_validate_dates_eveningstar]\n",
    "# list_of_list_new_sign = [list_new_sign_invertedhammer, list_new_sign_hammer, list_new_sign_piercing, list_new_sign_morningstar, list_new_sign_shootingstar, list_new_sign_hangingman, list_new_sign_darkcloudcover, list_new_sign_eveningstar]\n",
    "\n",
    "list_new_column_name_pos = ['CDLINVERTEDHAMMER_NEW', 'CDLHAMMER_NEW', 'CDLPIERCING_NEW', 'CDLMORNINGSTAR_NEW', 'CDLENGULFINGBULLISH_NEW']\n",
    "list_new_column_name_neg = ['CDLSHOOTINGSTAR_NEW', 'CDLHANGINGMAN_NEW', 'CDLDARKCLOUDCOVER_NEW', 'CDLEVENINGSTAR_NEW', 'CDLENGULFINGBEARISH_NEW']\n",
    "\n",
    "list_of_list_valid_dates_pos = [list_validate_dates_invertedhammer, list_validate_dates_hammer, list_validate_dates_piercing, list_validate_dates_morningstar, list_validate_dates_bullishengulfing]\n",
    "list_of_list_valid_dates_neg = [list_validate_dates_shootingstar, list_validate_dates_hangingman, list_validate_dates_darkcloudcover, list_validate_dates_eveningstar, list_validate_dates_bearishengulfing]\n",
    "\n",
    "# list_of_list_new_sign_pos = [list_new_sign_invertedhammer, list_new_sign_hammer, list_new_sign_piercing, list_new_sign_morningstar, list_new_sign_bullishengulfing]\n",
    "# list_of_list_new_sign_neg = [list_new_sign_shootingstar, list_new_sign_hangingman, list_new_sign_darkcloudcover, list_new_sign_eveningstar, list_new_sign_bearishengulfing]\n",
    "\n",
    "list_of_list_sign_pos = [list_sign_invertedhammer, list_sign_hammer, list_sign_piercing, list_sign_morningstar, list_sign_bullishengulfing]\n",
    "list_of_list_sign_neg = [list_sign_shootingstar, list_sign_hangingman, list_sign_darkcloudcover, list_sign_eveningstar, list_sign_bearishengulfing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(list_new_column_name_pos)):\n",
    "    df_dummy[list_new_column_name_pos[i]] = np.where(df_dummy['date'].isin(list_of_list_valid_dates_pos[i]), list_of_list_sign_pos[i], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(list_new_column_name_neg)):\n",
    "    df_dummy[list_new_column_name_neg[i]] = np.where(df_dummy['date'].isin(list_of_list_valid_dates_neg[i]), list_of_list_sign_neg[i], 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add risk and technical indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_technical_indicators_df(df_price_ohcl):\n",
    "    try:\n",
    "        o = df_price_ohcl['open'].values\n",
    "        c = df_price_ohcl['close'].values\n",
    "        h = df_price_ohcl['high'].values\n",
    "        l = df_price_ohcl['low'].values\n",
    "        v = df_price_ohcl['volume'].astype(float).values\n",
    "        \n",
    "        # Most data series are normalized by their series' mean\n",
    "        ta = df_price_ohcl.copy()\n",
    "        \n",
    "        #ta['reference_date'] = df_price_ohcl.index\n",
    "        \n",
    "        # All Moving Average\n",
    "        ta['MA5'] = tb.MA(c, timeperiod=5) #/ tb.MA(c, timeperiod=5).mean()\n",
    "        ta['MA10'] = tb.MA(c, timeperiod=10) #/ tb.MA(c, timeperiod=10).mean()\n",
    "        ta['MA20'] = tb.MA(c, timeperiod=20) #/ tb.MA(c, timeperiod=20).mean()\n",
    "        ta['MA60'] = tb.MA(c, timeperiod=60) #/ tb.MA(c, timeperiod=60).mean()\n",
    "        ta['MA120'] = tb.MA(c, timeperiod=120) #/ tb.MA(c, timeperiod=120).mean()\n",
    "        ta['volume_MA5'] = tb.MA(v, timeperiod=5) #/ tb.MA(v, timeperiod=5).mean()\n",
    "        ta['volume_MA10'] = tb.MA(v, timeperiod=10) #/ tb.MA(v, timeperiod=10).mean()\n",
    "        ta['volume_MA20'] = tb.MA(v, timeperiod=20) #/ tb.MA(v, timeperiod=20).mean()\n",
    "        \n",
    "        # Simple Moving Average (SMA)\n",
    "        ta['SMA5'] = tb.SMA(c, timeperiod=5) #/ tb.SMA(c, timeperiod=5).mean()\n",
    "        ta['SMA10'] = tb.SMA(c, timeperiod=10) #/ tb.SMA(c, timeperiod=10).mean()\n",
    "        ta['SMA20'] = tb.SMA(c, timeperiod=20) #/ tb.SMA(c, timeperiod=20).mean()\n",
    "        ta['SMA60'] = tb.SMA(c, timeperiod=60) #/ tb.SMA(c, timeperiod=60).mean()\n",
    "        ta['SMA120'] = tb.SMA(c, timeperiod=120) #/ tb.SMA(c, timeperiod=120).mean()\n",
    "        ta['volume_SMA5'] = tb.SMA(v, timeperiod=5) #/ tb.SMA(v, timeperiod=5).mean()\n",
    "        ta['volume_SMA10'] = tb.SMA(v, timeperiod=10) #/ tb.SMA(v, timeperiod=10).mean()\n",
    "        ta['volume_SMA20'] = tb.SMA(v, timeperiod=20) #/ tb.SMA(v, timeperiod=20).mean()\n",
    "        \n",
    "        # Weighted Moving Average (WMA)\n",
    "        ta['WMA5'] = tb.WMA(c, timeperiod=5) #/ tb.WMA(c, timeperiod=5).mean()\n",
    "        ta['WMA10'] = tb.WMA(c, timeperiod=10) #/ tb.WMA(c, timeperiod=10).mean()\n",
    "        ta['WMA20'] = tb.WMA(c, timeperiod=20) #/ tb.WMA(c, timeperiod=20).mean()\n",
    "        ta['WMA60'] = tb.WMA(c, timeperiod=60) #/ tb.WMA(c, timeperiod=60).mean()\n",
    "        ta['WMA120'] = tb.WMA(c, timeperiod=120) #/ tb.WMA(c, timeperiod=120).mean()\n",
    "        ta['volume_WMA5'] = tb.WMA(v, timeperiod=5) #/ tb.WMA(v, timeperiod=5).mean()\n",
    "        ta['volume_WMA10'] = tb.WMA(v, timeperiod=10) #/ tb.WMA(v, timeperiod=10).mean()\n",
    "        ta['volume_WMA20'] = tb.WMA(v, timeperiod=20) #/ tb.WMA(v, timeperiod=20).mean()\n",
    "        \n",
    "        # Exponential Moving Average (EMA)\n",
    "        ta['EMA5'] = tb.EMA(c, timeperiod=5) #/ tb.WMA(c, timeperiod=5).mean()\n",
    "        ta['EMA10'] = tb.EMA(c, timeperiod=10) #/ tb.WMA(c, timeperiod=10).mean()\n",
    "        ta['EMA20'] = tb.EMA(c, timeperiod=20) #/ tb.WMA(c, timeperiod=20).mean()\n",
    "        ta['EMA60'] = tb.EMA(c, timeperiod=60) #/ tb.WMA(c, timeperiod=60).mean()\n",
    "        ta['EMA120'] = tb.EMA(c, timeperiod=120) #/ tb.WMA(c, timeperiod=120).mean()\n",
    "        ta['volume_EMA5'] = tb.EMA(v, timeperiod=5) #/ tb.WMA(v, timeperiod=5).mean()\n",
    "        ta['volume_EMA10'] = tb.EMA(v, timeperiod=10) #/ tb.WMA(v, timeperiod=10).mean()\n",
    "        ta['volume_EMA20'] = tb.EMA(v, timeperiod=20) #/ tb.WMA(v, timeperiod=20).mean()        \n",
    "        \n",
    "        # William'%R (WILLR)\n",
    "        ta['WILLR_14'] = tb.WILLR(h, l, c, timeperiod=14)\n",
    "        \n",
    "        # Normalized Average True Range (NATR)\n",
    "        ta['NATR_14'] = tb.NATR(h, l, c, timeperiod=14)\n",
    "        \n",
    "        # Percentage Price Oscillator (PPO)\n",
    "        ta['PPO_12_26'] = tb.PPO(c, fastperiod=12, slowperiod=26, matype=0)\n",
    "        \n",
    "        # Commodity Channel Index (CCI)\n",
    "        ta['CCI_14'] = tb.CCI(h, l, c, timeperiod=14)\n",
    "        \n",
    "        # Average Directional Movement Index\n",
    "        ta['ADX_14'] = tb.ADX(h, l, c, timeperiod=14) #/ tb.ADX(h, l, c, timeperiod=14).mean()\n",
    "        \n",
    "        # Average Directional Movement Index Rating\n",
    "        ta['ADXR_14'] = tb.ADXR(h, l, c, timeperiod=14) #/ tb.ADXR(h, l, c, timeperiod=14).mean()\n",
    "\n",
    "        # Moving Average Convergence/Divergence\n",
    "        ta['MACD_12_26_9'] = tb.MACD(c, fastperiod=12, slowperiod=26, signalperiod=9)[0] #/ tb.MACD(c, fastperiod=12, slowperiod=26, signalperiod=9)[0].mean()\n",
    "        \n",
    "        # Relative Strength Index\n",
    "        ta['RSI_14'] = tb.RSI(c, timeperiod=14) #/ tb.RSI(c, timeperiod=14).mean()\n",
    "        \n",
    "        # Bollinger Bands\n",
    "        ta['BBANDS_U'] = tb.BBANDS(c, timeperiod=20, nbdevup=2, nbdevdn=2, matype=0)[0] #/ \\tb.BBANDS(c, timeperiod=5, nbdevup=2, nbdevdn=2, matype=0)[0].mean()\n",
    "        ta['BBANDS_M'] = tb.BBANDS(c, timeperiod=20, nbdevup=2, nbdevdn=2, matype=0)[1] #/ \\tb.BBANDS(c, timeperiod=5, nbdevup=2, nbdevdn=2, matype=0)[1].mean()\n",
    "        ta['BBANDS_L'] = tb.BBANDS(c, timeperiod=20, nbdevup=2, nbdevdn=2, matype=0)[2] #/ tb.BBANDS(c, timeperiod=5, nbdevup=2, nbdevdn=2, matype=0)[2].mean()\n",
    "\n",
    "        # Chaikin A/D Line\n",
    "        ta['AD'] = tb.AD(h, l, c, v) #/ tb.AD(h, l, c, v).mean()\n",
    "        \n",
    "        # Average True Range\n",
    "        ta['ATR'] = tb.ATR(h, l, c, timeperiod=14) #/ tb.ATR(h, l, c, timeperiod=14).mean()\n",
    "        \n",
    "        # Hilbert Transform - Dominant Cycle Period\n",
    "        ta['HT_DC'] = tb.HT_DCPERIOD(c) #/ tb.HT_DCPERIOD(c).mean()\n",
    "\n",
    "        # Parabolic SAR\n",
    "        ta['SAR'] = tb.SAR(h, l, acceleration=0.02, maximum=0.2)        \n",
    "        \n",
    "        # prices ratio\n",
    "        ta[\"ratio_high_open\"] = h / o\n",
    "        ta[\"ratio_low_open\"] = l / o\n",
    "        ta[\"ratio_close_open\"] = c / o\n",
    "        \n",
    "        return ta\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy = create_technical_indicators_df(df_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy = df_dummy.dropna()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create crypto index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy['time_to_chart_return'] = (df_dummy['close']/ df_dummy['close'].shift(1)) -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy['crypto_index'] = ((1 + df_dummy['time_to_chart_return']).cumprod()) * 1000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add log OHLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy['log_open'] = np.log(df_dummy['open'])\n",
    "df_dummy['log_high'] = np.log(df_dummy['high'])\n",
    "df_dummy['log_low'] = np.log(df_dummy['low'])\n",
    "df_dummy['log_close'] = np.log(df_dummy['close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop all Not a number values using drop method.\n",
    "df_dummy.dropna(inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_path = \"../../data/50_log\"\n",
    "export_filename = \"binance\" + \\\n",
    "                  \"_\" + asset_ticket + \\\n",
    "                  \"_\" + timestamp + \\\n",
    "                  \"_from_\" + datetime.datetime.strptime(start_date,'%d %b, %Y').strftime('%Y_%m_%d') + \\\n",
    "                  \"_to_\" + datetime.datetime.strptime(end_date,'%d %b, %Y').strftime('%Y_%m_%d') + \\\n",
    "                  \"_candlesticks_signals_processed_technical_indicators_and_crypto_index_log\"\n",
    "export_extension = \".csv\"\n",
    "full_export_path = os.path.join(export_path, export_filename + export_extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy.to_csv(full_export_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc_uol_ai_dissertation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0c0f2ae3d5d9aa27c4a2afc20f28a2482dc1006477ab22953abc78c31c7bb5b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
