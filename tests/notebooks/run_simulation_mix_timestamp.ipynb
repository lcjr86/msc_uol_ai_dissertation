{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Simulations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from configparser import ConfigParser\n",
    "\n",
    "from typing import Callable\n",
    "\n",
    "import gym\n",
    "import gym_anytrading\n",
    "\n",
    "from gym_anytrading.envs import CryptoEnvLogBLSH\n",
    "\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3 import A2C, PPO, DQN\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "import quantstats as qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "# print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get values from the config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['config_files/config_00a_mix.ini']\n"
     ]
    }
   ],
   "source": [
    "configur = ConfigParser()\n",
    "config_file_name = \"config_00a_mix.ini\"\n",
    "print (configur.read(os.path.join('config_files', config_file_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file_name_without_extension = config_file_name.replace(\".ini\", \"\")\n",
    "\n",
    "ccy = configur.get('data', 'ccy')\n",
    "data_frequency_train = configur.get('data', 'data_frequency_train')\n",
    "data_frequency_val = configur.get('data', 'data_frequency_val')\n",
    "\n",
    "window_size = configur.getint('environment', 'window_size')\n",
    "start_date = configur.get('environment', 'start_date')\n",
    "mid_date = configur.get('environment', 'mid_date')\n",
    "end_date = configur.get('environment', 'end_date')\n",
    "list_features = configur.get('environment', 'features').split(',')\n",
    "target = configur.get('environment', 'target')\n",
    "\n",
    "num_of_simulations = configur.getint('simulation', 'num_of_simulations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_process_data(ccy, data_frequency):\n",
    "    try:\n",
    "        \n",
    "        # Get the data\n",
    "        filename_data = 'binance_' + ccy + \"_\" + data_frequency + '_from_2017_01_01_to_2022_12_31_candlesticks_signals_processed_technical_indicators_and_crypto_index_log.csv'\n",
    "        fullpath_data = os.path.join('../../data/50_log/', filename_data)\n",
    "        df = pd.read_csv(fullpath_data)\n",
    "\n",
    "        # Converting Date Column to DateTime Type\n",
    "        df['Date'] = pd.to_datetime(df['formatted_open_time'])\n",
    "\n",
    "        # Setting the column as index\n",
    "        df.set_index('Date', inplace=True)\n",
    "\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_process_data(env):\n",
    "    start = env.frame_bound[0] - env.window_size\n",
    "    end = env.frame_bound[1]\n",
    "    prices = env.df.loc[:, target].to_numpy()[start:end]\n",
    "    signal_features = env.df.loc[:, list_features].to_numpy()[start:end]\n",
    "    dates = env.df.index.to_numpy()[start:end]\n",
    "    return prices, signal_features, dates\n",
    "\n",
    "class MyEnv(CryptoEnvLogBLSH):\n",
    "    _process_data = my_process_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = get_and_process_data(ccy, data_frequency_train)\n",
    "df_val = get_and_process_data(ccy, data_frequency_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train.shape: (46860, 94)\n",
      "df_val.shape: (1839, 94)\n"
     ]
    }
   ],
   "source": [
    "print(f'df_train.shape: {df_train.shape}')\n",
    "print(f'df_val.shape: {df_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date_id_train = int(df_train.index.get_loc(start_date))\n",
    "mid_date_id_train = int(df_train.index.get_loc(mid_date))\n",
    "mid_date_id_val = int(df_val.index.get_loc(mid_date))\n",
    "end_date_id_val = int(df_val.index.get_loc(end_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (92) does not match length of index (91)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/lcjr86/de Jesus Lallement Dropbox/Luiz Carlos de Jesus Junior/msc_uol_ai_dissertation/notebooks/simulations/run_simulation_mix_timestamp.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lcjr86/de%20Jesus%20Lallement%20Dropbox/Luiz%20Carlos%20de%20Jesus%20Junior/msc_uol_ai_dissertation/notebooks/simulations/run_simulation_mix_timestamp.ipynb#X21sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m \u001b[39m# Export quantstats\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lcjr86/de%20Jesus%20Lallement%20Dropbox/Luiz%20Carlos%20de%20Jesus%20Junior/msc_uol_ai_dissertation/notebooks/simulations/run_simulation_mix_timestamp.ipynb#X21sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m qs\u001b[39m.\u001b[39mextend_pandas()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/lcjr86/de%20Jesus%20Lallement%20Dropbox/Luiz%20Carlos%20de%20Jesus%20Junior/msc_uol_ai_dissertation/notebooks/simulations/run_simulation_mix_timestamp.ipynb#X21sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m net_worth \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mSeries(env\u001b[39m.\u001b[39;49mhistory[\u001b[39m'\u001b[39;49m\u001b[39mtotal_profit_percentage\u001b[39;49m\u001b[39m'\u001b[39;49m], index\u001b[39m=\u001b[39;49mdf_val\u001b[39m.\u001b[39;49mindex[mid_date_id_val\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m:end_date_id_val])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lcjr86/de%20Jesus%20Lallement%20Dropbox/Luiz%20Carlos%20de%20Jesus%20Junior/msc_uol_ai_dissertation/notebooks/simulations/run_simulation_mix_timestamp.ipynb#X21sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m returns \u001b[39m=\u001b[39m net_worth\u001b[39m.\u001b[39mpct_change()\u001b[39m.\u001b[39miloc[\u001b[39m1\u001b[39m:]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lcjr86/de%20Jesus%20Lallement%20Dropbox/Luiz%20Carlos%20de%20Jesus%20Junior/msc_uol_ai_dissertation/notebooks/simulations/run_simulation_mix_timestamp.ipynb#X21sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m qs\u001b[39m.\u001b[39mreports\u001b[39m.\u001b[39mhtml(returns, output\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mquantstats_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m config_file_name_without_extension \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_sim_id_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(sim_id) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.html\u001b[39m\u001b[39m'\u001b[39m, title\u001b[39m=\u001b[39mconfig_file_name_without_extension \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_sim_id_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(sim_id), download_filename\u001b[39m=\u001b[39mos\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39mresults\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mplots\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mquantstats\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mquantstats_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m config_file_name_without_extension \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_sim_id_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(sim_id) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.html\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/msc_uol_ai_dissertation/lib/python3.8/site-packages/pandas/core/series.py:462\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    460\u001b[0m     index \u001b[39m=\u001b[39m default_index(\u001b[39mlen\u001b[39m(data))\n\u001b[1;32m    461\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(data):\n\u001b[0;32m--> 462\u001b[0m     com\u001b[39m.\u001b[39;49mrequire_length_match(data, index)\n\u001b[1;32m    464\u001b[0m \u001b[39m# create/copy the manager\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, (SingleBlockManager, SingleArrayManager)):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/msc_uol_ai_dissertation/lib/python3.8/site-packages/pandas/core/common.py:561\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    558\u001b[0m \u001b[39mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[0;32m--> 561\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    562\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLength of values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    563\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    564\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoes not match length of index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    565\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    566\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (92) does not match length of index (91)"
     ]
    }
   ],
   "source": [
    "#list_models = ['A2C', 'PPO', 'DQN', 'RANDOM']\n",
    "list_models = ['A2C']\n",
    "\n",
    "path_tensorboard = os.path.join(\"tensorboard\", config_file_name.replace(\".ini\", \"\"))\n",
    "\n",
    "df_sim_results = pd.DataFrame()\n",
    "\n",
    "#setting up our environment for training \n",
    "env_maker = lambda: MyEnv(df=df_train, frame_bound=(start_date_id_train,mid_date_id_train), window_size=window_size)\n",
    "env = DummyVecEnv([env_maker])\n",
    "\n",
    "sim_id = 1\n",
    "\n",
    "for model_name in list_models:\n",
    "\n",
    "    if(model_name == 'A2C'):\n",
    "        model = A2C('MlpPolicy', env, verbose=0, tensorboard_log=path_tensorboard) \n",
    "    elif(model_name == 'PPO'):\n",
    "        model = PPO('MlpPolicy', env, batch_size=1024, verbose=0, tensorboard_log=path_tensorboard)\n",
    "    elif(model_name == 'DQN'):\n",
    "        model = DQN('MlpPolicy', env, batch_size=1024, verbose=0, tensorboard_log=path_tensorboard)\n",
    "\n",
    "    #setting the learning timesteps\n",
    "    model.learn(total_timesteps=(mid_date_id_train - start_date_id_train))\n",
    "    \n",
    "    # Export the model components\n",
    "    \n",
    "    if(model_name == 'A2C'):\n",
    "        model.save(os.path.join('save_models_components', 'model', 'model_' + model_name + \"_\" + config_file_name_without_extension))\n",
    "        model.policy.save(os.path.join('save_models_components', 'policy', 'policy_' + model_name + \"_\" + config_file_name_without_extension))\n",
    "    elif(model_name == 'PPO'):\n",
    "        model.save(os.path.join('save_models_components', 'model', 'model_' + model_name + \"_\" + config_file_name_without_extension))\n",
    "        model.policy.save(os.path.join('save_models_components', 'policy', 'policy_' + model_name + \"_\" + config_file_name_without_extension))\n",
    "    elif(model_name == 'DQN'):\n",
    "        model.save(os.path.join('save_models_components', 'model', 'model_' + model_name + \"_\" + config_file_name_without_extension))\n",
    "        model.save_replay_buffer(os.path.join('save_models_components', 'replay_buffer', 'replay_buffer_' + model_name + \"_\" + config_file_name_without_extension))\n",
    "        model.policy.save(os.path.join('save_models_components', 'policy', 'policy_' + model_name + \"_\" + config_file_name_without_extension))\n",
    "\n",
    "    df_sim_results_temp = pd.DataFrame(columns=['total_reward_cash', 'total_profit_percentage', 'fmt_total_profit_percentage', 'num_of_trades'])\n",
    "\n",
    "    list_sim_id = []\n",
    "\n",
    "    for i in range(num_of_simulations):   \n",
    "        \n",
    "        list_sim_id.append(sim_id)\n",
    "\n",
    "        # Check the progress\n",
    "        if(i % 10 == 0):\n",
    "            print(i)\n",
    "\n",
    "        env = MyEnv(df=df_val, frame_bound=(mid_date_id_val,end_date_id_val), window_size=window_size, log=True)\n",
    "\n",
    "        #Setting up the Agent Environment\n",
    "        obs = env.reset()\n",
    "        while True: \n",
    "            obs = obs[np.newaxis, ...]\n",
    "            if(model_name == 'RANDOM'):\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action, _states = model.predict(obs)\n",
    "            obs, rewards, done, info = env.step(action)\n",
    "            if done:\n",
    "                df_sim_results_temp = df_sim_results_temp.append(info, ignore_index=True, sort=False)\n",
    "                break\n",
    "\n",
    "        # Export robot actions plot\n",
    "        fig = env.render_all()\n",
    "        fig.write_html(os.path.join('results', 'plots', 'robot_actions', 'robot_actions_' + config_file_name_without_extension + '_sim_id_' + str(sim_id) + '.html'))\n",
    "\n",
    "        # Export quantstats\n",
    "        qs.extend_pandas()\n",
    "        net_worth = pd.Series(env.history['total_profit_percentage'], index=df_val.index[mid_date_id_val+1:end_date_id_val])\n",
    "        returns = net_worth.pct_change().iloc[1:]\n",
    "        qs.reports.html(returns, output='quantstats_' + config_file_name_without_extension + '_sim_id_' + str(sim_id) + '.html', title=config_file_name_without_extension + '_sim_id_' + str(sim_id), download_filename=os.path.join('results', 'plots', 'quantstats', 'quantstats_' + config_file_name_without_extension + '_sim_id_' + str(sim_id) + '.html'))\n",
    "\n",
    "        sim_id = sim_id + 1\n",
    "        \n",
    "    df_sim_results_temp['sim_id'] = list_sim_id\n",
    "    df_sim_results_temp['ccy'] = ccy\n",
    "    df_sim_results_temp['data_frequency_train'] = data_frequency_train\n",
    "    df_sim_results_temp['data_frequency_val'] = data_frequency_val\n",
    "    df_sim_results_temp['window_size'] = window_size\n",
    "    df_sim_results_temp['start_date'] = start_date\n",
    "    df_sim_results_temp['mid_date'] = mid_date\n",
    "    df_sim_results_temp['end_date'] = end_date\n",
    "    df_sim_results_temp['list_features'] = str(list_features)\n",
    "    df_sim_results_temp['model_type'] = model_name \n",
    "    df_sim_results_temp['num_of_simulations'] = num_of_simulations   \n",
    "\n",
    "    df_sim_results = pd.concat([df_sim_results, df_sim_results_temp], axis=0)\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim_results = df_sim_results.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim_results = df_sim_results.drop_duplicates()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_sim_results[(df_sim_results['model_type'] == 'A2C')]\n",
    "x[x.total_reward_cash == x.total_reward_cash.max()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\":(15, 10)})\n",
    "\n",
    "str_title = f'ccy:{ccy} | data_frequency_train:{data_frequency_train} | data_frequency_val:{data_frequency_val} | window_size:{window_size} | start_run_date:{mid_date} | end_run_date:{end_date} | lenght list_features:{len(list_features)} | num_of_simulations:{num_of_simulations}'\n",
    "\n",
    "file_export_plot_sim_results = config_file_name.replace(\".ini\", \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df_sim_results, x=\"fmt_total_profit_percentage\", y=\"model_type\").set(title=str_title)\n",
    "plt.savefig(os.path.join('results', 'plots', 'total_profit_percentage', 'box_plot_' + file_export_plot_sim_results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df_sim_results, x=\"fmt_total_profit_percentage\", hue=\"model_type\", kde=True).set(title=str_title)\n",
    "plt.savefig(os.path.join('results', 'plots', 'total_profit_percentage', 'hist_plot_' + file_export_plot_sim_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df_sim_results, x=\"num_of_trades\", hue=\"model_type\", kde=True).set(title=str_title)\n",
    "plt.savefig(os.path.join('results', 'plots', 'num_of_trades', 'hist_plot_' + file_export_plot_sim_results))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_export_sim_results = config_file_name.replace(\".ini\", \".csv\")\n",
    "fullpath_export_sim_results = os.path.join('results', 'data', 'sim_results_' + file_export_sim_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim_results.to_csv(fullpath_export_sim_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc_uol_ai_dissertation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0c0f2ae3d5d9aa27c4a2afc20f28a2482dc1006477ab22953abc78c31c7bb5b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
