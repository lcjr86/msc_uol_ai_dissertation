{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Simulations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from configparser import ConfigParser\n",
    "\n",
    "from typing import Callable\n",
    "\n",
    "import gym\n",
    "import gym_anytrading\n",
    "\n",
    "from gym_anytrading.envs import CryptoEnvLogBLSH\n",
    "\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines3 import A2C, PPO, DQN\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set some 'global' parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "#list_asset_ticket = [\"BTCUSDT\", \"ETHUSDT\", \"BNBUSDT\"]\n",
    "list_asset_ticket = [\"BNBUSDT\"]\n",
    "list_timestamp = [\"1d\", \"1h\", \"15m\"] \n",
    "#list_timestamp = [\"5m\"]  \n",
    "list_feat = [1, 2, 3]\n",
    "\n",
    "list_config_file_name = []\n",
    "for asset_ticket in list_asset_ticket:\n",
    "    for timestamp in list_timestamp:\n",
    "        for feat in list_feat:\n",
    "            config_file_name_temp = \"config_msc_\" + asset_ticket + \"_\" + timestamp + \"_feat_package\" + str(feat) + \".ini\"\n",
    "            list_config_file_name.append(config_file_name_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get and process the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method that get the data from DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_process_data(ccy, data_frequency, start_date, end_date):\n",
    "    try:\n",
    "        \n",
    "        # Get the data\n",
    "        db_address = 'sqlite:///../../data/db/crypto_msc.db'\n",
    "        engine = create_engine(db_address, echo=False)\n",
    "        sqlite_connection = engine.connect()\n",
    "\n",
    "        input_tbl_name = \"tbl_all_features\" + \"_\" + ccy + \"_\" + data_frequency\n",
    "        \n",
    "        sql_command = \"SELECT * FROM \" + input_tbl_name\n",
    "\n",
    "        if(start_date!=\"\" and end_date!=\"\"):\n",
    "            \n",
    "            sd = datetime.datetime.strptime(start_date,'%d %b, %Y').strftime('%Y-%m-%d')\n",
    "            ed = datetime.datetime.strptime(end_date,'%d %b, %Y').strftime('%Y-%m-%d')\n",
    "\n",
    "            sql_append = \" WHERE \" + \"date(date) >= \" + \"'\" + sd + \"'\" + \" AND date(date) <= \" + \"'\" + ed + \"'\"\n",
    "            sql_command = sql_command + sql_append\n",
    "\n",
    "        df = pd.read_sql(sql_command, sqlite_connection)\n",
    "\n",
    "        sqlite_connection.close()\n",
    "\n",
    "        # Converting Date Column to DateTime Type\n",
    "        # Set the index on the dataframe\n",
    "        df['date_index'] = df['date']\n",
    "        df.set_index('date_index', inplace=True)\n",
    "\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method that executes the process (run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    try:\n",
    "        for element in list_config_file_name:\n",
    "            \n",
    "            # Get the config file\n",
    "            configur = ConfigParser()\n",
    "            config_file_name = element\n",
    "            print (configur.read(os.path.join('../config_files', config_file_name)))\n",
    "            \n",
    "            config_file_name_without_extension = config_file_name.replace(\".ini\", \"\")\n",
    "\n",
    "            # Get all the relevant values\n",
    "            ccy = configur.get('data', 'ccy')\n",
    "            data_frequency_train = configur.get('data', 'data_frequency_train')\n",
    "            data_frequency_val = configur.get('data', 'data_frequency_val')\n",
    "\n",
    "            window_size = configur.getint('environment', 'window_size')\n",
    "            start_date = configur.get('environment', 'start_date')\n",
    "            mid_date = configur.get('environment', 'mid_date')\n",
    "            end_date = configur.get('environment', 'end_date')\n",
    "            list_features = configur.get('environment', 'features').split(',')\n",
    "            target = configur.get('environment', 'target')\n",
    "\n",
    "            num_of_simulations = configur.getint('simulation', 'num_of_simulations')\n",
    "\n",
    "            def my_process_data(env):\n",
    "                start = env.frame_bound[0] - env.window_size\n",
    "                end = env.frame_bound[1]\n",
    "                prices = env.df.loc[:, target].to_numpy()[start:end]\n",
    "                signal_features = env.df.loc[:, list_features].to_numpy()[start:end]\n",
    "                dates = env.df.index.to_numpy()[start:end]\n",
    "                return prices, signal_features, dates\n",
    "\n",
    "            class MyEnv(CryptoEnvLogBLSH):\n",
    "                _process_data = my_process_data\n",
    "\n",
    "            # Format the data\n",
    "            start_date_temp = datetime.datetime.strptime(start_date,'%Y-%m-%d %H:%M:%S')\n",
    "            start_date_temp2 = start_date_temp + datetime.timedelta(days=-(window_size+1))\n",
    "            start_date_db = start_date_temp2.strftime('%d %b, %Y')\n",
    "            end_date_db = datetime.datetime.strptime(end_date,'%Y-%m-%d %H:%M:%S').strftime('%d %b, %Y')\n",
    "\n",
    "            df_train = get_and_process_data(ccy, data_frequency_train, start_date_db, end_date_db)\n",
    "            df_val = get_and_process_data(ccy, data_frequency_val, start_date_db, end_date_db)\n",
    "\n",
    "            start_date_id_train = int(df_train.index.get_loc(datetime.datetime.strptime(start_date,'%Y-%m-%d %H:%M:%S').strftime('%Y-%m-%d %H:%M:%S.%f')))\n",
    "            mid_date_id_train = int(df_train.index.get_loc(datetime.datetime.strptime(mid_date,'%Y-%m-%d %H:%M:%S').strftime('%Y-%m-%d %H:%M:%S.%f')))\n",
    "            mid_date_id_val = int(df_val.index.get_loc(datetime.datetime.strptime(mid_date,'%Y-%m-%d %H:%M:%S').strftime('%Y-%m-%d %H:%M:%S.%f')))\n",
    "            end_date_id_val = int(df_val.index.get_loc(datetime.datetime.strptime(end_date,'%Y-%m-%d %H:%M:%S').strftime('%Y-%m-%d %H:%M:%S.%f')))\n",
    "\n",
    "            def make_env(df, frame_bound, window_size, env_id: str, rank: int, seed: int = 0) -> Callable:\n",
    "                \"\"\"\n",
    "                Utility function for multiprocessed env.\n",
    "                \n",
    "                :param env_id: (str) the environment ID\n",
    "                :param num_env: (int) the number of environment you wish to have in subprocesses\n",
    "                :param seed: (int) the inital seed for RNG\n",
    "                :param rank: (int) index of the subprocess\n",
    "                :return: (Callable)\n",
    "                \"\"\"\n",
    "                def _init() -> gym.Env:\n",
    "                    env = MyEnv(df=df, frame_bound=frame_bound, window_size=window_size)\n",
    "                    env.seed(seed + rank)\n",
    "                    return env\n",
    "                set_random_seed(seed)\n",
    "                return _init \n",
    "\n",
    "            list_models = ['A2C', 'PPO', 'DQN', 'RANDOM']\n",
    "\n",
    "            path_tensorboard = os.path.join(\"tensorboard\", config_file_name.replace(\".ini\", \"\"))\n",
    "\n",
    "            df_sim_results = pd.DataFrame()\n",
    "            df_robot_actions_and_env_final = pd.DataFrame()\n",
    "\n",
    "            num_cpu = 8  # Number of processes to use\n",
    "            env_id = 'CryptoEnvLogBLSH-v1'\n",
    "\n",
    "            #setting up our environment for training \n",
    "            env = SubprocVecEnv([make_env(df_train, (start_date_id_train, mid_date_id_train), window_size, env_id, i) for i in range(num_cpu)])\n",
    "\n",
    "            sim_id = 1\n",
    "\n",
    "            for model_name in list_models:\n",
    "\n",
    "                if(model_name == 'A2C'):\n",
    "                    model = A2C('MlpPolicy', env, verbose=0, tensorboard_log=path_tensorboard) \n",
    "                elif(model_name == 'PPO'):\n",
    "                    model = PPO('MlpPolicy', env, batch_size=1024, verbose=0, tensorboard_log=path_tensorboard)\n",
    "                elif(model_name == 'DQN'):\n",
    "                    model = DQN('MlpPolicy', env, batch_size=1024, verbose=0, tensorboard_log=path_tensorboard)\n",
    "\n",
    "                #setting the learning timesteps\n",
    "                model.learn(total_timesteps=(mid_date_id_train - start_date_id_train))\n",
    "                \n",
    "                # Export the model components\n",
    "                \n",
    "                if(model_name == 'A2C'):\n",
    "                    model.save(os.path.join('../save_models_components', 'model', 'model_' + model_name + \"_\" + config_file_name_without_extension))\n",
    "                    model.policy.save(os.path.join('../save_models_components', 'policy', 'policy_' + model_name + \"_\" + config_file_name_without_extension))\n",
    "                elif(model_name == 'PPO'):\n",
    "                    model.save(os.path.join('../save_models_components', 'model', 'model_' + model_name + \"_\" + config_file_name_without_extension))\n",
    "                    model.policy.save(os.path.join('../save_models_components', 'policy', 'policy_' + model_name + \"_\" + config_file_name_without_extension))\n",
    "                elif(model_name == 'DQN'):\n",
    "                    model.save(os.path.join('../save_models_components', 'model', 'model_' + model_name + \"_\" + config_file_name_without_extension))\n",
    "                    model.save_replay_buffer(os.path.join('../save_models_components', 'replay_buffer', 'replay_buffer_' + model_name + \"_\" + config_file_name_without_extension))\n",
    "                    model.policy.save(os.path.join('../save_models_components', 'policy', 'policy_' + model_name + \"_\" + config_file_name_without_extension))\n",
    "\n",
    "                df_sim_results_temp = pd.DataFrame(columns=['total_reward_cash', 'total_profit_percentage', 'fmt_total_profit_percentage', 'num_of_trades'])\n",
    "                df_robot_actions_and_env_temp = pd.DataFrame(columns=['dates', 'prices', 'actions', 'total_reward_cash', 'total_profit_percentage', 'fmt_total_profit_percentage', 'num_of_trades', 'sim_id'])\n",
    "\n",
    "                list_sim_id = []\n",
    "\n",
    "                for i in range(num_of_simulations):   \n",
    "                    \n",
    "                    list_sim_id.append(sim_id)\n",
    "\n",
    "                    # # Check the progress\n",
    "                    # if(i % 100 == 0):\n",
    "                    #     print(f'model_name:{model_name} - sim_id:{sim_id}')\n",
    "\n",
    "                    env = MyEnv(df=df_val, frame_bound=(mid_date_id_val,end_date_id_val), window_size=window_size)\n",
    "\n",
    "                    #Setting up the Agent Environment\n",
    "                    obs = env.reset()\n",
    "                    \n",
    "                    while True: \n",
    "                        obs = obs[np.newaxis, ...]\n",
    "\n",
    "                        if(model_name == 'RANDOM'):\n",
    "                            action = env.action_space.sample()\n",
    "                        else:\n",
    "                            action, _states = model.predict(obs)\n",
    "                        \n",
    "                        obs, rewards, done, info = env.step(action)\n",
    "                        \n",
    "                        if done:\n",
    "                            df_sim_results_temp = df_sim_results_temp.append(info, ignore_index=True, sort=False)\n",
    "                            break\n",
    "\n",
    "                    # Export robot actions plot and data\n",
    "                    fig, df_robot_actions = env.render_all()\n",
    "\n",
    "                    # Export the history of details (the info dict inside of the environment)\n",
    "                    df_sim_env_data = pd.DataFrame.from_dict(env.history)\n",
    "\n",
    "                    # Merge robot actions data + sim env data\n",
    "                    df_sim_env_data_initial = pd.DataFrame(columns=['total_reward_cash', 'total_profit_percentage', 'fmt_total_profit_percentage', 'num_of_trades'])\n",
    "                    for i in range(0, window_size + 1):\n",
    "                        df_sim_env_data_initial = df_sim_env_data_initial.append(pd.Series([0, 0, 0, 0], index=df_sim_env_data_initial.columns), ignore_index=True)\n",
    "\n",
    "                    df_sim_env_data_temp = df_sim_env_data_initial.append(df_sim_env_data, ignore_index=True)\n",
    "                    \n",
    "                    df_robot_actions_and_env_temp = pd.merge(df_robot_actions, df_sim_env_data_temp, left_index=True, right_index=True, how = \"outer\")\n",
    "                    df_robot_actions_and_env_temp['sim_id'] = sim_id\n",
    "\n",
    "                    df_robot_actions_and_env_final = pd.concat([df_robot_actions_and_env_final, df_robot_actions_and_env_temp], axis=0)\n",
    "\n",
    "                    sim_id = sim_id + 1\n",
    "                    \n",
    "                df_sim_results_temp['sim_id'] = list_sim_id\n",
    "                df_sim_results_temp['ccy'] = ccy\n",
    "                df_sim_results_temp['data_frequency_train'] = data_frequency_train\n",
    "                df_sim_results_temp['data_frequency_val'] = data_frequency_val\n",
    "                df_sim_results_temp['window_size'] = window_size\n",
    "                df_sim_results_temp['start_date'] = start_date\n",
    "                df_sim_results_temp['mid_date'] = mid_date\n",
    "                df_sim_results_temp['end_date'] = end_date\n",
    "                df_sim_results_temp['target'] = target\n",
    "                df_sim_results_temp['list_features'] = str(list_features)\n",
    "                df_sim_results_temp['model_type'] = model_name \n",
    "                df_sim_results_temp['num_of_simulations'] = num_of_simulations  \n",
    "\n",
    "                df_sim_results = pd.concat([df_sim_results, df_sim_results_temp], axis=0)\n",
    "\n",
    "            # Pre-process the results\n",
    "            df_sim_results = df_sim_results.reset_index(drop=True)\n",
    "            df_sim_results = df_sim_results.drop_duplicates()\n",
    "\n",
    "            ## SIMULATION RESULTS\n",
    "\n",
    "            # Format data type\n",
    "            df_sim_results['start_date'] = pd.to_datetime(df_sim_results['start_date'])\n",
    "            df_sim_results['mid_date'] = pd.to_datetime(df_sim_results['mid_date'])\n",
    "            df_sim_results['end_date'] = pd.to_datetime(df_sim_results['end_date'])\n",
    "\n",
    "            # Write to the db\n",
    "            db_address = 'sqlite:///../results/data/db/simulation_msc.db'\n",
    "            engine = create_engine(db_address, echo=False)\n",
    "            sqlite_connection = engine.connect()\n",
    "\n",
    "            output_tbl_name = \"tbl_simulation_results_\" + config_file_name_without_extension\n",
    "\n",
    "            df_sim_results.to_sql(output_tbl_name, sqlite_connection, if_exists='replace', index=False)\n",
    "\n",
    "            sqlite_connection.close()\n",
    "\n",
    "            ## ROBOT ACTIONS and ENV RESULTS\n",
    "\n",
    "            # Format data type\n",
    "            df_robot_actions_and_env_final['dates'] = pd.to_datetime(df_robot_actions_and_env_final['dates'])\n",
    "            df_robot_actions_and_env_final['total_reward_cash'] = df_robot_actions_and_env_final['total_reward_cash'].astype(float)\n",
    "            df_robot_actions_and_env_final['total_profit_percentage'] = df_robot_actions_and_env_final['total_profit_percentage'].astype(float)\n",
    "            df_robot_actions_and_env_final['fmt_total_profit_percentage'] = df_robot_actions_and_env_final['fmt_total_profit_percentage'].astype(float)\n",
    "            df_robot_actions_and_env_final['num_of_trades'] = df_robot_actions_and_env_final['num_of_trades'].astype(float) \n",
    "\n",
    "            # Write to the db\n",
    "            db_address = 'sqlite:///../results/data/db/simulation_msc.db'\n",
    "            engine = create_engine(db_address, echo=False)\n",
    "            sqlite_connection = engine.connect()\n",
    "\n",
    "            output_tbl_name = \"tbl_robot_actions_and_env_\" + config_file_name_without_extension\n",
    "\n",
    "            df_robot_actions_and_env_final.to_sql(output_tbl_name, sqlite_connection, if_exists='replace', index=False)\n",
    "\n",
    "            sqlite_connection.close()\n",
    "\n",
    "            # Generate plots\n",
    "            str_title = f\"ccy:{ccy} | data_frequency_train:{data_frequency_train} | data_frequency_val:{data_frequency_val} | window_size:{window_size}<br>start_run_date:{mid_date} | end_run_date:{end_date} | lenght list_features:{len(list_features)} | num_of_simulations:{num_of_simulations}\"\n",
    "            file_export_plot_sim_results = config_file_name.replace(\".ini\", \"\")\n",
    "            \n",
    "            fig = px.box(df_sim_results, y=\"fmt_total_profit_percentage\", color=\"model_type\", points=\"all\", color_discrete_sequence=[ \"#FF7F0E\", \"#00CC96\", \"#10aded\", \"#8A56EF\"],  width=800, height=600)\n",
    "            fig.update_layout(title=str_title, font={'size': 8})\n",
    "            fig.write_html(os.path.join('../results', 'plots', 'total_profit_percentage', 'box_plot_' + file_export_plot_sim_results + '.html'))\n",
    "\n",
    "            fig = px.histogram(df_sim_results, x=\"fmt_total_profit_percentage\", color=\"model_type\", color_discrete_sequence=[ \"#FF7F0E\", \"#00CC96\", \"#10aded\", \"#8A56EF\"],  width=800, height=600, marginal=\"rug\", # can be `box`, `violin`\n",
    "                                    hover_data=['total_reward_cash','fmt_total_profit_percentage', 'num_of_trades', 'sim_id'])\n",
    "            fig.update_layout(title=str_title, font={'size': 8})\n",
    "            fig.write_html(os.path.join('../results', 'plots', 'total_profit_percentage', 'hist_plot_' + file_export_plot_sim_results + '.html'))\n",
    "            \n",
    "            fig = px.histogram(df_sim_results, x=\"num_of_trades\", color=\"model_type\", color_discrete_sequence=[ \"#FF7F0E\", \"#00CC96\", \"#10aded\", \"#8A56EF\"],  width=800, height=600, marginal=\"rug\", # can be `box`, `violin`\n",
    "                                    hover_data=['total_reward_cash','fmt_total_profit_percentage', 'num_of_trades', 'sim_id'])\n",
    "            fig.update_layout(title=str_title, font={'size': 8})\n",
    "            fig.write_html(os.path.join('../results', 'plots', 'num_of_trades', 'hist_plot_' + file_export_plot_sim_results + '.html'))  \n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../config_files/config_msc_BNBUSDT_1d_feat_package1.ini']\n",
      "['../config_files/config_msc_BNBUSDT_1d_feat_package2.ini']\n",
      "['../config_files/config_msc_BNBUSDT_1d_feat_package3.ini']\n",
      "['../config_files/config_msc_BNBUSDT_1h_feat_package1.ini']\n",
      "['../config_files/config_msc_BNBUSDT_1h_feat_package2.ini']\n",
      "['../config_files/config_msc_BNBUSDT_1h_feat_package3.ini']\n",
      "['../config_files/config_msc_BNBUSDT_15m_feat_package1.ini']\n",
      "['../config_files/config_msc_BNBUSDT_15m_feat_package2.ini']\n",
      "['../config_files/config_msc_BNBUSDT_15m_feat_package3.ini']\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc_uol_ai_dissertation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0c0f2ae3d5d9aa27c4a2afc20f28a2482dc1006477ab22953abc78c31c7bb5b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
