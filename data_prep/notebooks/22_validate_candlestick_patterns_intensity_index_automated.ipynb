{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate candlestick patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import utils as u\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "from configparser import ConfigParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set some 'global' parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../config_files/config_candlestick_patterns.ini']\n"
     ]
    }
   ],
   "source": [
    "configur = ConfigParser()\n",
    "print (configur.read('../config_files/config_candlestick_patterns.ini'))\n",
    "#print (\"Sections : \", configur.sections())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get and process the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method that executes the process (run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    try:\n",
    "        # Parameters\n",
    "        list_asset_ticket = [\"BTCUSDT\", \"ETHUSDT\", \"BNBUSDT\"]\n",
    "        list_timestamp = [\"1d\", \"1h\", \"30m\", \"15m\", \"5m\"]\n",
    "        start_date = \"1 Jan, 2017\"\n",
    "        end_date = \"31 Dec, 2022\"\n",
    "        window_size = configur.getint('candlestick_patterns', 'window_size')\n",
    "        slope_size = configur.getint('candlestick_patterns', 'slope_size')\n",
    "\n",
    "        for asset_ticket in list_asset_ticket:\n",
    "            for timestamp in list_timestamp:\n",
    "\n",
    "                # Data file parameters\n",
    "                input_data_path = '../../data/10_candlesticks_signals_raw'\n",
    "                input_data_filename = \"binance\" + \\\n",
    "                                \"_\" + asset_ticket + \\\n",
    "                                \"_\" + timestamp + \\\n",
    "                                \"_from_\" + datetime.datetime.strptime(start_date,'%d %b, %Y').strftime('%Y_%m_%d') + \\\n",
    "                                \"_to_\" + datetime.datetime.strptime(end_date,'%d %b, %Y').strftime('%Y_%m_%d') + \\\n",
    "                                \"_candlesticks_signals_raw\"\n",
    "                input_data_extension = \".csv\"\n",
    "                full_path_input_data = os.path.join(input_data_path, input_data_filename + input_data_extension)\n",
    "\n",
    "                df = pd.read_csv(full_path_input_data)\n",
    "\n",
    "                # Set the index on the dataframe\n",
    "                df['date_index'] = df['date']\n",
    "                df.set_index('date_index', inplace=True)\n",
    "\n",
    "                # Set some parameters\n",
    "                window_size = configur.getint('candlestick_patterns', 'window_size')\n",
    "                slope_size = configur.getint('candlestick_patterns', 'slope_size')\n",
    "\n",
    "                # Get the dates from the bullish candlesticks patterns\n",
    "                list_dates_invertedhammer = df[df['CDLINVERTEDHAMMER'] == 100]['date'].to_list()\n",
    "                list_dates_hammer = df[df['CDLHAMMER'] == 100]['date'].to_list()\n",
    "                list_dates_piercing = df[df['CDLPIERCING'] == 100]['date'].to_list()\n",
    "                list_dates_morningstar = df[df['CDLMORNINGSTAR'] == 100]['date'].to_list()\n",
    "                list_dates_bullishengulfing = df[df['CDLENGULFINGBULLISH'] == 100]['date'].to_list()\n",
    "\n",
    "                # Get all dates\n",
    "                list_all_dates = df['date'].to_list()\n",
    "\n",
    "                # Run the checks to identify the real candlesticks with reversal\n",
    "                list_validate_dates_invertedhammer = []\n",
    "                list_new_sign_invertedhammer = []\n",
    "                list_sign_invertedhammer = [0] * len(list_all_dates)\n",
    "                for date in list_dates_invertedhammer:\n",
    "                    i = u.check_intensity_trend(df, date, window_size, slope_size)\n",
    "                    if(i >= 0):\n",
    "                        list_validate_dates_invertedhammer.append(date)\n",
    "                        list_new_sign_invertedhammer.append(i*100)\n",
    "                        list_sign_invertedhammer[list_all_dates.index(date)] = i*100\n",
    "\n",
    "\n",
    "                list_validate_dates_hammer = []\n",
    "                list_new_sign_hammer = []\n",
    "                list_sign_hammer = [0] * len(list_all_dates)\n",
    "                for date in list_dates_hammer:\n",
    "                    i = u.check_intensity_trend(df, date, window_size, slope_size)\n",
    "                    if(i >= 0):    \n",
    "                        list_validate_dates_hammer.append(date)\n",
    "                        list_new_sign_hammer.append(i*100)\n",
    "                        list_sign_hammer[list_all_dates.index(date)] = i*100\n",
    "\n",
    "                list_validate_dates_piercing = []\n",
    "                list_new_sign_piercing = []\n",
    "                list_sign_piercing = [0] * len(list_all_dates)\n",
    "                for date in list_dates_piercing:\n",
    "                    i = u.check_intensity_trend(df, date, window_size, slope_size)\n",
    "                    if(i >= 0):\n",
    "                        list_validate_dates_piercing.append(date)\n",
    "                        list_new_sign_piercing.append(i*100)\n",
    "                        list_sign_piercing[list_all_dates.index(date)] = i*100\n",
    "\n",
    "                list_validate_dates_morningstar = []\n",
    "                list_new_sign_morningstar = []\n",
    "                list_sign_morningstar = [0] * len(list_all_dates)\n",
    "                for date in list_dates_morningstar:\n",
    "                    i = u.check_intensity_trend(df, date, window_size, slope_size)\n",
    "                    if(i >= 0):\n",
    "                        list_validate_dates_morningstar.append(date)\n",
    "                        list_new_sign_morningstar.append(i*100)\n",
    "                        list_sign_morningstar[list_all_dates.index(date)] = i*100\n",
    "\n",
    "                list_validate_dates_bullishengulfing = []\n",
    "                list_new_sign_bullishengulfing = []\n",
    "                list_sign_bullishengulfing = [0] * len(list_all_dates)\n",
    "                for date in list_dates_bullishengulfing:\n",
    "                    i = u.check_intensity_trend(df, date, window_size, slope_size)\n",
    "                    # print(f'date:{date}|i:{i}')\n",
    "                    if(i >= 0):\n",
    "                        list_validate_dates_bullishengulfing.append(date)\n",
    "                        list_new_sign_bullishengulfing.append(i*100)\n",
    "                        list_sign_bullishengulfing[list_all_dates.index(date)] = i*100\n",
    "\n",
    "                # Get the dates from the bearish candlesticks patterns\n",
    "                list_dates_shootingstar = df[df['CDLSHOOTINGSTAR'] == -100]['date'].to_list()\n",
    "                list_dates_hangingman = df[df['CDLHANGINGMAN'] == -100]['date'].to_list()\n",
    "                list_dates_darkcloudcover = df[df['CDLDARKCLOUDCOVER'] == -100]['date'].to_list()\n",
    "                list_dates_eveningstar = df[df['CDLEVENINGSTAR'] == -100]['date'].to_list()\n",
    "                list_dates_bearishengulfing = df[df['CDLENGULFINGBEARISH'] == -100]['date'].to_list()\n",
    "\n",
    "                # Run the checks to identify the real candlesticks with reversal\n",
    "                list_validate_dates_shootingstar = []\n",
    "                list_new_sign_shootingstar = []\n",
    "                list_sign_shootingstar = [0] * len(list_all_dates)\n",
    "                for date in list_dates_shootingstar:\n",
    "                    i = u.check_intensity_trend(df, date, window_size, slope_size)\n",
    "                    if (i<=0):\n",
    "                        list_validate_dates_shootingstar.append(date)\n",
    "                        list_new_sign_shootingstar.append(i*100)\n",
    "                        list_sign_shootingstar[list_all_dates.index(date)] = i*100\n",
    "\n",
    "\n",
    "                list_validate_dates_hangingman = []\n",
    "                list_new_sign_hangingman = []\n",
    "                list_sign_hangingman = [0] * len(list_all_dates)\n",
    "                for date in list_dates_hangingman:\n",
    "                    i = u.check_intensity_trend(df, date, window_size, slope_size)\n",
    "                    if (i<=0):\n",
    "                        list_validate_dates_hangingman.append(date)\n",
    "                        list_new_sign_hangingman.append(i*100)\n",
    "                        list_sign_hangingman[list_all_dates.index(date)] = i*100\n",
    "\n",
    "                list_validate_dates_darkcloudcover = []\n",
    "                list_new_sign_darkcloudcover = []\n",
    "                list_sign_darkcloudcover = [0] * len(list_all_dates)\n",
    "                for date in list_dates_darkcloudcover:\n",
    "                    i = u.check_intensity_trend(df, date, window_size, slope_size)\n",
    "                    if (i<=0):\n",
    "                        list_validate_dates_darkcloudcover.append(date)\n",
    "                        list_new_sign_darkcloudcover.append(i*100)\n",
    "                        list_sign_darkcloudcover[list_all_dates.index(date)] = i*100  \n",
    "\n",
    "                list_validate_dates_eveningstar = []\n",
    "                list_new_sign_eveningstar = []\n",
    "                list_sign_eveningstar = [0] * len(list_all_dates)\n",
    "                for date in list_dates_eveningstar:\n",
    "                    i = u.check_intensity_trend(df, date, window_size, slope_size)\n",
    "                    if (i<=0):\n",
    "                        list_validate_dates_eveningstar.append(date)\n",
    "                        list_new_sign_eveningstar.append(i*100)\n",
    "                        list_sign_eveningstar[list_all_dates.index(date)] = i*100\n",
    "\n",
    "                list_validate_dates_bearishengulfing = []\n",
    "                list_new_sign_bearishengulfing = []\n",
    "                list_sign_bearishengulfing = [0] * len(list_all_dates)\n",
    "                for date in list_dates_bearishengulfing:\n",
    "                    i = u.check_intensity_trend(df, date, window_size, slope_size)\n",
    "                    if (i<=0):\n",
    "                        list_validate_dates_bearishengulfing.append(date)\n",
    "                        list_new_sign_bearishengulfing.append(i*100)\n",
    "                        list_sign_bearishengulfing[list_all_dates.index(date)] = i*100\n",
    "\n",
    "                # Create the data with the validation results\n",
    "\n",
    "                list_new_column_name_pos = ['CDLINVERTEDHAMMER_NEW', 'CDLHAMMER_NEW', 'CDLPIERCING_NEW', 'CDLMORNINGSTAR_NEW', 'CDLENGULFINGBULLISH_NEW']\n",
    "                list_new_column_name_neg = ['CDLSHOOTINGSTAR_NEW', 'CDLHANGINGMAN_NEW', 'CDLDARKCLOUDCOVER_NEW', 'CDLEVENINGSTAR_NEW', 'CDLENGULFINGBEARISH_NEW']\n",
    "\n",
    "                list_of_list_valid_dates_pos = [list_validate_dates_invertedhammer, list_validate_dates_hammer, list_validate_dates_piercing, list_validate_dates_morningstar, list_validate_dates_bullishengulfing]\n",
    "                list_of_list_valid_dates_neg = [list_validate_dates_shootingstar, list_validate_dates_hangingman, list_validate_dates_darkcloudcover, list_validate_dates_eveningstar, list_validate_dates_bearishengulfing]\n",
    "\n",
    "                list_of_list_sign_pos = [list_sign_invertedhammer, list_sign_hammer, list_sign_piercing, list_sign_morningstar, list_sign_bullishengulfing]\n",
    "                list_of_list_sign_neg = [list_sign_shootingstar, list_sign_hangingman, list_sign_darkcloudcover, list_sign_eveningstar, list_sign_bearishengulfing]\n",
    "\n",
    "                for i in range(0, len(list_new_column_name_pos)):\n",
    "                    df[list_new_column_name_pos[i]] = np.where(df['date'].isin(list_of_list_valid_dates_pos[i]), list_of_list_sign_pos[i], 0)\n",
    "\n",
    "                for i in range(0, len(list_new_column_name_neg)):\n",
    "                    df[list_new_column_name_neg[i]] = np.where(df['date'].isin(list_of_list_valid_dates_neg[i]), list_of_list_sign_neg[i], 0)\n",
    "\n",
    "                # Export the data\n",
    "                export_path = \"../../data/20_candlesticks_signals_processed\"\n",
    "                export_filename = \"binance\" + \\\n",
    "                                \"_\" + asset_ticket + \\\n",
    "                                \"_\" + timestamp + \\\n",
    "                                \"_from_\" + datetime.datetime.strptime(start_date,'%d %b, %Y').strftime('%Y_%m_%d') + \\\n",
    "                                \"_to_\" + datetime.datetime.strptime(end_date,'%d %b, %Y').strftime('%Y_%m_%d') + \\\n",
    "                                \"_candlesticks_signals_processed\"\n",
    "                export_extension = \".csv\"\n",
    "                full_export_path = os.path.join(export_path, export_filename + export_extension)            \n",
    "\n",
    "                df.to_csv(full_export_path, index=False)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0c0f2ae3d5d9aa27c4a2afc20f28a2482dc1006477ab22953abc78c31c7bb5b2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('msc_uol_ai_dissertation')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
