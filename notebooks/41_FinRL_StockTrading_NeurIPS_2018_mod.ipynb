{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL/blob/master/FinRL_StockTrading_NeurIPS_2018.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXaoZs2lh1hi"
   },
   "source": [
    "# Deep Reinforcement Learning for Stock Trading from Scratch: Multiple Stock Trading\n",
    "\n",
    "* **Pytorch Version** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sApkDlD9LIZv"
   },
   "source": [
    "<a id='0'></a>\n",
    "# Part 1. Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjLD2TZSLKZ-"
   },
   "source": [
    "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
    "\n",
    "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
    "\n",
    "\n",
    "* Action: The action space describes the allowed actions that the agent interacts with the\n",
    "environment. Normally, a ∈ A includes three actions: a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
    "selling, holding, and buying one stock. Also, an action can be carried upon multiple shares. We use\n",
    "an action space {−k, ..., −1, 0, 1, ..., k}, where k denotes the number of shares. For example, \"Buy\n",
    "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
    "\n",
    "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
    "values at state s′ and s, respectively\n",
    "\n",
    "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
    "our trading agent observes many different features to better learn in an interactive environment.\n",
    "\n",
    "* Environment: Dow 30 consituents\n",
    "\n",
    "\n",
    "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ffsre789LY08"
   },
   "source": [
    "<a id='1'></a>\n",
    "# Part 2. Getting Started- Load Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osBHhVysOEzi"
   },
   "source": [
    "\n",
    "<a id='1.2'></a>\n",
    "## 2.2. Check if the additional packages needed are present, if not install them. \n",
    "* Yahoo Finance API\n",
    "* pandas\n",
    "* numpy\n",
    "* matplotlib\n",
    "* stockstats\n",
    "* OpenAI gym\n",
    "* stable-baselines\n",
    "* tensorflow\n",
    "* pyfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGv01K8Sh1hn"
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 2.3. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lPqeTTwoh1hn",
    "outputId": "10b08480-3a0c-4826-8e51-f94ce97ab84a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "from finrl.finrl_meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.finrl_meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.finrl_meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from finrl.finrl_meta.data_processor import DataProcessor\n",
    "\n",
    "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "from pprint import pprint\n",
    "\n",
    "import sys\n",
    "#sys.path.append(\"../FinRL-Library\")\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A289rQWMh1hq"
   },
   "source": [
    "<a id='2'></a>\n",
    "# Part 3. Get Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_path = '../data'\n",
    "input_data_filename = 'binance_BTCUSDT_1m_from_2020_01_01_to_2021_12_31_candlesticks_signals_processed'\n",
    "input_data_extension = \".csv\"\n",
    "full_path_input_data = os.path.join(input_data_path, input_data_filename + input_data_extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(full_path_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CV3HrZHLh1hy",
    "outputId": "5267773c-399c-4ec9-d4d5-13ab1e4cced0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048956, 38)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open_time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>close_time</th>\n",
       "      <th>quote_asset_volumne</th>\n",
       "      <th>number_of_trades</th>\n",
       "      <th>taker_buy_base_asset_volume</th>\n",
       "      <th>...</th>\n",
       "      <th>CDLINVERTEDHAMMER_NEW</th>\n",
       "      <th>CDLHAMMER_NEW</th>\n",
       "      <th>CDLPIERCING_NEW</th>\n",
       "      <th>CDLMORNINGSTAR_NEW</th>\n",
       "      <th>CDLENGULFINGBULLISH_NEW</th>\n",
       "      <th>CDLSHOOTINGSTAR_NEW</th>\n",
       "      <th>CDLHANGINGMAN_NEW</th>\n",
       "      <th>CDLDARKCLOUDCOVER_NEW</th>\n",
       "      <th>CDLEVENINGSTAR_NEW</th>\n",
       "      <th>CDLENGULFINGBEARISH_NEW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1577836800000</td>\n",
       "      <td>7195.24</td>\n",
       "      <td>7196.25</td>\n",
       "      <td>7183.14</td>\n",
       "      <td>7186.68</td>\n",
       "      <td>51.642812</td>\n",
       "      <td>1577836859999</td>\n",
       "      <td>371233.518355</td>\n",
       "      <td>493</td>\n",
       "      <td>19.598230</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1577836860000</td>\n",
       "      <td>7187.67</td>\n",
       "      <td>7188.06</td>\n",
       "      <td>7182.20</td>\n",
       "      <td>7184.03</td>\n",
       "      <td>7.248148</td>\n",
       "      <td>1577836919999</td>\n",
       "      <td>52080.127788</td>\n",
       "      <td>135</td>\n",
       "      <td>2.031772</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1577836920000</td>\n",
       "      <td>7184.41</td>\n",
       "      <td>7184.71</td>\n",
       "      <td>7180.26</td>\n",
       "      <td>7182.43</td>\n",
       "      <td>11.681677</td>\n",
       "      <td>1577836979999</td>\n",
       "      <td>83903.741635</td>\n",
       "      <td>202</td>\n",
       "      <td>5.479244</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1577836980000</td>\n",
       "      <td>7183.83</td>\n",
       "      <td>7188.94</td>\n",
       "      <td>7182.49</td>\n",
       "      <td>7185.94</td>\n",
       "      <td>10.025391</td>\n",
       "      <td>1577837039999</td>\n",
       "      <td>72033.226649</td>\n",
       "      <td>136</td>\n",
       "      <td>3.294966</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1577837040000</td>\n",
       "      <td>7185.54</td>\n",
       "      <td>7185.54</td>\n",
       "      <td>7178.64</td>\n",
       "      <td>7179.78</td>\n",
       "      <td>14.911105</td>\n",
       "      <td>1577837099999</td>\n",
       "      <td>107066.521825</td>\n",
       "      <td>161</td>\n",
       "      <td>2.369033</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       open_time     open     high      low    close     volume  \\\n",
       "0  1577836800000  7195.24  7196.25  7183.14  7186.68  51.642812   \n",
       "1  1577836860000  7187.67  7188.06  7182.20  7184.03   7.248148   \n",
       "2  1577836920000  7184.41  7184.71  7180.26  7182.43  11.681677   \n",
       "3  1577836980000  7183.83  7188.94  7182.49  7185.94  10.025391   \n",
       "4  1577837040000  7185.54  7185.54  7178.64  7179.78  14.911105   \n",
       "\n",
       "      close_time  quote_asset_volumne  number_of_trades  \\\n",
       "0  1577836859999        371233.518355               493   \n",
       "1  1577836919999         52080.127788               135   \n",
       "2  1577836979999         83903.741635               202   \n",
       "3  1577837039999         72033.226649               136   \n",
       "4  1577837099999        107066.521825               161   \n",
       "\n",
       "   taker_buy_base_asset_volume  ...  CDLINVERTEDHAMMER_NEW  CDLHAMMER_NEW  \\\n",
       "0                    19.598230  ...                      0              0   \n",
       "1                     2.031772  ...                      0              0   \n",
       "2                     5.479244  ...                      0              0   \n",
       "3                     3.294966  ...                      0              0   \n",
       "4                     2.369033  ...                      0              0   \n",
       "\n",
       "  CDLPIERCING_NEW CDLMORNINGSTAR_NEW  CDLENGULFINGBULLISH_NEW  \\\n",
       "0               0                  0                        0   \n",
       "1               0                  0                        0   \n",
       "2               0                  0                        0   \n",
       "3               0                  0                        0   \n",
       "4               0                  0                        0   \n",
       "\n",
       "   CDLSHOOTINGSTAR_NEW  CDLHANGINGMAN_NEW  CDLDARKCLOUDCOVER_NEW  \\\n",
       "0                    0                  0                      0   \n",
       "1                    0                  0                      0   \n",
       "2                    0                  0                      0   \n",
       "3                    0                  0                      0   \n",
       "4                    0                  0                      0   \n",
       "\n",
       "   CDLEVENINGSTAR_NEW  CDLENGULFINGBEARISH_NEW  \n",
       "0                   0                        0  \n",
       "1                   0                        0  \n",
       "2                   0                        0  \n",
       "3                   0                        0  \n",
       "4                   0                        0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['open_time', 'open', 'high', 'low', 'close', 'volume', 'close_time',\n",
       "       'quote_asset_volumne', 'number_of_trades',\n",
       "       'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore',\n",
       "       'formatted_open_time', 'formatted_close_time', 'upper_shadow',\n",
       "       'lower_shadow', 'real_body', 'CDLINVERTEDHAMMER', 'CDLHAMMER',\n",
       "       'CDLPIERCING', 'CDLMORNINGSTAR', 'CDLSHOOTINGSTAR', 'CDLHANGINGMAN',\n",
       "       'CDLDARKCLOUDCOVER', 'CDLEVENINGSTAR', 'CDLENGULFING',\n",
       "       'CDLENGULFINGBULLISH', 'CDLENGULFINGBEARISH', 'CDLINVERTEDHAMMER_NEW',\n",
       "       'CDLHAMMER_NEW', 'CDLPIERCING_NEW', 'CDLMORNINGSTAR_NEW',\n",
       "       'CDLENGULFINGBULLISH_NEW', 'CDLSHOOTINGSTAR_NEW', 'CDLHANGINGMAN_NEW',\n",
       "       'CDLDARKCLOUDCOVER_NEW', 'CDLEVENINGSTAR_NEW',\n",
       "       'CDLENGULFINGBEARISH_NEW'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {'formatted_open_time':'date'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tic\"] = 'BTCUSDT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col_selected = df[['date', 'tic', 'open', 'high', 'low', 'close', 'volume',\n",
    "        'upper_shadow', 'lower_shadow', 'real_body', \n",
    "        'CDLINVERTEDHAMMER_NEW', 'CDLHAMMER_NEW', 'CDLMORNINGSTAR_NEW', 'CDLENGULFINGBULLISH_NEW', \n",
    "        'CDLSHOOTINGSTAR_NEW', 'CDLHANGINGMAN_NEW', 'CDLEVENINGSTAR_NEW', 'CDLENGULFINGBEARISH_NEW']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>upper_shadow</th>\n",
       "      <th>lower_shadow</th>\n",
       "      <th>real_body</th>\n",
       "      <th>CDLINVERTEDHAMMER_NEW</th>\n",
       "      <th>CDLHAMMER_NEW</th>\n",
       "      <th>CDLMORNINGSTAR_NEW</th>\n",
       "      <th>CDLENGULFINGBULLISH_NEW</th>\n",
       "      <th>CDLSHOOTINGSTAR_NEW</th>\n",
       "      <th>CDLHANGINGMAN_NEW</th>\n",
       "      <th>CDLEVENINGSTAR_NEW</th>\n",
       "      <th>CDLENGULFINGBEARISH_NEW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>7195.24</td>\n",
       "      <td>7196.25</td>\n",
       "      <td>7183.14</td>\n",
       "      <td>7186.68</td>\n",
       "      <td>51.642812</td>\n",
       "      <td>1.01</td>\n",
       "      <td>3.54</td>\n",
       "      <td>8.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01 00:01:00</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>7187.67</td>\n",
       "      <td>7188.06</td>\n",
       "      <td>7182.20</td>\n",
       "      <td>7184.03</td>\n",
       "      <td>7.248148</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.83</td>\n",
       "      <td>3.64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01 00:02:00</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>7184.41</td>\n",
       "      <td>7184.71</td>\n",
       "      <td>7180.26</td>\n",
       "      <td>7182.43</td>\n",
       "      <td>11.681677</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.17</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01 00:03:00</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>7183.83</td>\n",
       "      <td>7188.94</td>\n",
       "      <td>7182.49</td>\n",
       "      <td>7185.94</td>\n",
       "      <td>10.025391</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.34</td>\n",
       "      <td>2.11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01 00:04:00</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>7185.54</td>\n",
       "      <td>7185.54</td>\n",
       "      <td>7178.64</td>\n",
       "      <td>7179.78</td>\n",
       "      <td>14.911105</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.14</td>\n",
       "      <td>5.76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date      tic     open     high      low    close  \\\n",
       "0  2020-01-01 00:00:00  BTCUSDT  7195.24  7196.25  7183.14  7186.68   \n",
       "1  2020-01-01 00:01:00  BTCUSDT  7187.67  7188.06  7182.20  7184.03   \n",
       "2  2020-01-01 00:02:00  BTCUSDT  7184.41  7184.71  7180.26  7182.43   \n",
       "3  2020-01-01 00:03:00  BTCUSDT  7183.83  7188.94  7182.49  7185.94   \n",
       "4  2020-01-01 00:04:00  BTCUSDT  7185.54  7185.54  7178.64  7179.78   \n",
       "\n",
       "      volume  upper_shadow  lower_shadow  real_body  CDLINVERTEDHAMMER_NEW  \\\n",
       "0  51.642812          1.01          3.54       8.56                      0   \n",
       "1   7.248148          0.39          1.83       3.64                      0   \n",
       "2  11.681677          0.30          2.17       1.98                      0   \n",
       "3  10.025391          3.00          1.34       2.11                      0   \n",
       "4  14.911105          0.00          1.14       5.76                      0   \n",
       "\n",
       "   CDLHAMMER_NEW  CDLMORNINGSTAR_NEW  CDLENGULFINGBULLISH_NEW  \\\n",
       "0              0                   0                        0   \n",
       "1              0                   0                        0   \n",
       "2              0                   0                        0   \n",
       "3              0                   0                        0   \n",
       "4              0                   0                        0   \n",
       "\n",
       "   CDLSHOOTINGSTAR_NEW  CDLHANGINGMAN_NEW  CDLEVENINGSTAR_NEW  \\\n",
       "0                    0                  0                   0   \n",
       "1                    0                  0                   0   \n",
       "2                    0                  0                   0   \n",
       "3                    0                  0                   0   \n",
       "4                    0                  0                   0   \n",
       "\n",
       "   CDLENGULFINGBEARISH_NEW  \n",
       "0                        0  \n",
       "1                        0  \n",
       "2                        0  \n",
       "3                        0  \n",
       "4                        0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_col_selected.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqC6c40Zh1iH"
   },
   "source": [
    "# Part 4: Preprocess Data\n",
    "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
    "* Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
    "* Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007–2008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PmKP-1ii3RLS",
    "outputId": "0708badb-77ef-4c86-f77c-6525f0e8934d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/msc_uol_ai_dissertation/lib/python3.8/site-packages/finrl/finrl_meta/preprocessor/preprocessors.py:154: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/msc_uol_ai_dissertation/lib/python3.8/site-packages/finrl/finrl_meta/preprocessor/preprocessors.py:154: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/msc_uol_ai_dissertation/lib/python3.8/site-packages/finrl/finrl_meta/preprocessor/preprocessors.py:154: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/msc_uol_ai_dissertation/lib/python3.8/site-packages/finrl/finrl_meta/preprocessor/preprocessors.py:154: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/msc_uol_ai_dissertation/lib/python3.8/site-packages/finrl/finrl_meta/preprocessor/preprocessors.py:154: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/msc_uol_ai_dissertation/lib/python3.8/site-packages/finrl/finrl_meta/preprocessor/preprocessors.py:154: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/msc_uol_ai_dissertation/lib/python3.8/site-packages/finrl/finrl_meta/preprocessor/preprocessors.py:154: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/msc_uol_ai_dissertation/lib/python3.8/site-packages/finrl/finrl_meta/preprocessor/preprocessors.py:154: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineer(\n",
    "                    use_technical_indicator=True,\n",
    "                    tech_indicator_list = [\"macd\", \"boll_ub\", \"boll_lb\", \"rsi_30\", \"cci_30\", \"dx_30\", \"close_30_sma\", \"close_60_sma\"],\n",
    "                    use_vix=False,\n",
    "                    use_turbulence=False,\n",
    "                    user_defined_feature = False)\n",
    "\n",
    "processed = fe.preprocess_data(df_col_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QsYaY0Dh1iw"
   },
   "source": [
    "<a id='4'></a>\n",
    "# Part 5. Design Environment\n",
    "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
    "\n",
    "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
    "\n",
    "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TOhcryx44bb"
   },
   "source": [
    "## Training data split:\n",
    "## Trade data split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W0qaVGjLtgbI",
    "outputId": "ca8d1a43-ffc3-4fc3-efa9-4de9a9065842"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784385\n",
      "264570\n"
     ]
    }
   ],
   "source": [
    "train = data_split(processed, '2020-01-01','2021-06-30')\n",
    "trade = data_split(processed, '2021-06-30','2021-12-31')\n",
    "print(len(train))\n",
    "print(len(trade))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "p52zNCOhTtLR",
    "outputId": "b3ad3e10-376f-4186-f875-0331708c5e14"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>upper_shadow</th>\n",
       "      <th>lower_shadow</th>\n",
       "      <th>real_body</th>\n",
       "      <th>...</th>\n",
       "      <th>CDLEVENINGSTAR_NEW</th>\n",
       "      <th>CDLENGULFINGBEARISH_NEW</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>784380</th>\n",
       "      <td>2021-06-29 23:55:00</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>35858.08</td>\n",
       "      <td>35858.09</td>\n",
       "      <td>35830.36</td>\n",
       "      <td>35850.37</td>\n",
       "      <td>41.739582</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20.01</td>\n",
       "      <td>7.71</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-41.231184</td>\n",
       "      <td>36110.212018</td>\n",
       "      <td>35790.596982</td>\n",
       "      <td>41.757816</td>\n",
       "      <td>-131.336690</td>\n",
       "      <td>50.030617</td>\n",
       "      <td>35979.158333</td>\n",
       "      <td>35965.902500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784381</th>\n",
       "      <td>2021-06-29 23:56:00</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>35850.38</td>\n",
       "      <td>35925.29</td>\n",
       "      <td>35850.37</td>\n",
       "      <td>35914.00</td>\n",
       "      <td>58.950362</td>\n",
       "      <td>11.29</td>\n",
       "      <td>0.01</td>\n",
       "      <td>63.62</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-36.693908</td>\n",
       "      <td>36088.377477</td>\n",
       "      <td>35795.031523</td>\n",
       "      <td>46.574800</td>\n",
       "      <td>-76.648525</td>\n",
       "      <td>14.307052</td>\n",
       "      <td>35977.260667</td>\n",
       "      <td>35964.135667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784382</th>\n",
       "      <td>2021-06-29 23:57:00</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>35914.00</td>\n",
       "      <td>35931.94</td>\n",
       "      <td>35900.30</td>\n",
       "      <td>35931.93</td>\n",
       "      <td>16.280007</td>\n",
       "      <td>0.01</td>\n",
       "      <td>13.70</td>\n",
       "      <td>17.93</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-31.290586</td>\n",
       "      <td>36065.778232</td>\n",
       "      <td>35802.837768</td>\n",
       "      <td>47.832506</td>\n",
       "      <td>-51.123894</td>\n",
       "      <td>11.498641</td>\n",
       "      <td>35977.024667</td>\n",
       "      <td>35962.999833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784383</th>\n",
       "      <td>2021-06-29 23:58:00</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>35931.88</td>\n",
       "      <td>35935.00</td>\n",
       "      <td>35844.85</td>\n",
       "      <td>35857.84</td>\n",
       "      <td>26.735525</td>\n",
       "      <td>3.12</td>\n",
       "      <td>12.99</td>\n",
       "      <td>74.04</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-32.610938</td>\n",
       "      <td>36048.284201</td>\n",
       "      <td>35801.060799</td>\n",
       "      <td>43.459132</td>\n",
       "      <td>-84.403884</td>\n",
       "      <td>27.398003</td>\n",
       "      <td>35973.028000</td>\n",
       "      <td>35960.910167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784384</th>\n",
       "      <td>2021-06-29 23:59:00</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>35857.84</td>\n",
       "      <td>35928.92</td>\n",
       "      <td>35830.12</td>\n",
       "      <td>35911.73</td>\n",
       "      <td>70.776395</td>\n",
       "      <td>17.19</td>\n",
       "      <td>27.72</td>\n",
       "      <td>53.89</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-28.974851</td>\n",
       "      <td>36027.632456</td>\n",
       "      <td>35808.288544</td>\n",
       "      <td>47.098557</td>\n",
       "      <td>-69.425668</td>\n",
       "      <td>30.921991</td>\n",
       "      <td>35970.085667</td>\n",
       "      <td>35960.689000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date      tic      open      high       low     close  \\\n",
       "784380  2021-06-29 23:55:00  BTCUSDT  35858.08  35858.09  35830.36  35850.37   \n",
       "784381  2021-06-29 23:56:00  BTCUSDT  35850.38  35925.29  35850.37  35914.00   \n",
       "784382  2021-06-29 23:57:00  BTCUSDT  35914.00  35931.94  35900.30  35931.93   \n",
       "784383  2021-06-29 23:58:00  BTCUSDT  35931.88  35935.00  35844.85  35857.84   \n",
       "784384  2021-06-29 23:59:00  BTCUSDT  35857.84  35928.92  35830.12  35911.73   \n",
       "\n",
       "           volume  upper_shadow  lower_shadow  real_body  ...  \\\n",
       "784380  41.739582          0.01         20.01       7.71  ...   \n",
       "784381  58.950362         11.29          0.01      63.62  ...   \n",
       "784382  16.280007          0.01         13.70      17.93  ...   \n",
       "784383  26.735525          3.12         12.99      74.04  ...   \n",
       "784384  70.776395         17.19         27.72      53.89  ...   \n",
       "\n",
       "        CDLEVENINGSTAR_NEW  CDLENGULFINGBEARISH_NEW       macd       boll_ub  \\\n",
       "784380                   0                        0 -41.231184  36110.212018   \n",
       "784381                   0                        0 -36.693908  36088.377477   \n",
       "784382                   0                        0 -31.290586  36065.778232   \n",
       "784383                   0                        0 -32.610938  36048.284201   \n",
       "784384                   0                        0 -28.974851  36027.632456   \n",
       "\n",
       "             boll_lb     rsi_30      cci_30      dx_30  close_30_sma  \\\n",
       "784380  35790.596982  41.757816 -131.336690  50.030617  35979.158333   \n",
       "784381  35795.031523  46.574800  -76.648525  14.307052  35977.260667   \n",
       "784382  35802.837768  47.832506  -51.123894  11.498641  35977.024667   \n",
       "784383  35801.060799  43.459132  -84.403884  27.398003  35973.028000   \n",
       "784384  35808.288544  47.098557  -69.425668  30.921991  35970.085667   \n",
       "\n",
       "        close_60_sma  \n",
       "784380  35965.902500  \n",
       "784381  35964.135667  \n",
       "784382  35962.999833  \n",
       "784383  35960.910167  \n",
       "784384  35960.689000  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "k9zU9YaTTvFq",
    "outputId": "72213585-39a3-4bff-c031-874ec0ca06f9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>upper_shadow</th>\n",
       "      <th>lower_shadow</th>\n",
       "      <th>real_body</th>\n",
       "      <th>...</th>\n",
       "      <th>CDLEVENINGSTAR_NEW</th>\n",
       "      <th>CDLENGULFINGBEARISH_NEW</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-06-30 00:00:00</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>35911.72</td>\n",
       "      <td>35941.75</td>\n",
       "      <td>35868.84</td>\n",
       "      <td>35924.04</td>\n",
       "      <td>60.951928</td>\n",
       "      <td>17.71</td>\n",
       "      <td>42.88</td>\n",
       "      <td>12.32</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-24.813872</td>\n",
       "      <td>36016.914824</td>\n",
       "      <td>35811.410176</td>\n",
       "      <td>47.891159</td>\n",
       "      <td>-47.501402</td>\n",
       "      <td>25.261039</td>\n",
       "      <td>35965.887000</td>\n",
       "      <td>35959.781500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-30 00:01:00</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>35924.03</td>\n",
       "      <td>35971.25</td>\n",
       "      <td>35850.00</td>\n",
       "      <td>35901.60</td>\n",
       "      <td>49.714898</td>\n",
       "      <td>47.22</td>\n",
       "      <td>51.60</td>\n",
       "      <td>22.43</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-23.061153</td>\n",
       "      <td>36008.122908</td>\n",
       "      <td>35812.277092</td>\n",
       "      <td>46.575236</td>\n",
       "      <td>-47.674618</td>\n",
       "      <td>13.227638</td>\n",
       "      <td>35960.226667</td>\n",
       "      <td>35959.701833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-30 00:02:00</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>35901.60</td>\n",
       "      <td>35921.43</td>\n",
       "      <td>35830.00</td>\n",
       "      <td>35869.61</td>\n",
       "      <td>80.065702</td>\n",
       "      <td>19.83</td>\n",
       "      <td>39.61</td>\n",
       "      <td>31.99</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-23.977043</td>\n",
       "      <td>35990.932415</td>\n",
       "      <td>35815.557585</td>\n",
       "      <td>44.761418</td>\n",
       "      <td>-74.272915</td>\n",
       "      <td>18.875646</td>\n",
       "      <td>35954.054333</td>\n",
       "      <td>35959.528667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-30 00:03:00</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>35867.91</td>\n",
       "      <td>35892.49</td>\n",
       "      <td>35830.00</td>\n",
       "      <td>35861.47</td>\n",
       "      <td>56.834397</td>\n",
       "      <td>24.58</td>\n",
       "      <td>31.47</td>\n",
       "      <td>6.44</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-25.070723</td>\n",
       "      <td>35975.283518</td>\n",
       "      <td>35818.057482</td>\n",
       "      <td>44.307219</td>\n",
       "      <td>-81.920150</td>\n",
       "      <td>18.875646</td>\n",
       "      <td>35946.216000</td>\n",
       "      <td>35958.743000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-30 00:04:00</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>35861.44</td>\n",
       "      <td>35920.29</td>\n",
       "      <td>35844.72</td>\n",
       "      <td>35847.26</td>\n",
       "      <td>41.738493</td>\n",
       "      <td>58.85</td>\n",
       "      <td>2.54</td>\n",
       "      <td>14.18</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-26.775450</td>\n",
       "      <td>35960.503204</td>\n",
       "      <td>35819.385796</td>\n",
       "      <td>43.509915</td>\n",
       "      <td>-70.129566</td>\n",
       "      <td>7.737266</td>\n",
       "      <td>35937.452667</td>\n",
       "      <td>35956.125667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date      tic      open      high       low     close  \\\n",
       "0  2021-06-30 00:00:00  BTCUSDT  35911.72  35941.75  35868.84  35924.04   \n",
       "1  2021-06-30 00:01:00  BTCUSDT  35924.03  35971.25  35850.00  35901.60   \n",
       "2  2021-06-30 00:02:00  BTCUSDT  35901.60  35921.43  35830.00  35869.61   \n",
       "3  2021-06-30 00:03:00  BTCUSDT  35867.91  35892.49  35830.00  35861.47   \n",
       "4  2021-06-30 00:04:00  BTCUSDT  35861.44  35920.29  35844.72  35847.26   \n",
       "\n",
       "      volume  upper_shadow  lower_shadow  real_body  ...  CDLEVENINGSTAR_NEW  \\\n",
       "0  60.951928         17.71         42.88      12.32  ...                   0   \n",
       "1  49.714898         47.22         51.60      22.43  ...                   0   \n",
       "2  80.065702         19.83         39.61      31.99  ...                   0   \n",
       "3  56.834397         24.58         31.47       6.44  ...                   0   \n",
       "4  41.738493         58.85          2.54      14.18  ...                   0   \n",
       "\n",
       "   CDLENGULFINGBEARISH_NEW       macd       boll_ub       boll_lb     rsi_30  \\\n",
       "0                        0 -24.813872  36016.914824  35811.410176  47.891159   \n",
       "1                        0 -23.061153  36008.122908  35812.277092  46.575236   \n",
       "2                        0 -23.977043  35990.932415  35815.557585  44.761418   \n",
       "3                        0 -25.070723  35975.283518  35818.057482  44.307219   \n",
       "4                        0 -26.775450  35960.503204  35819.385796  43.509915   \n",
       "\n",
       "      cci_30      dx_30  close_30_sma  close_60_sma  \n",
       "0 -47.501402  25.261039  35965.887000  35959.781500  \n",
       "1 -47.674618  13.227638  35960.226667  35959.701833  \n",
       "2 -74.272915  18.875646  35954.054333  35959.528667  \n",
       "3 -81.920150  18.875646  35946.216000  35958.743000  \n",
       "4 -70.129566   7.737266  35937.452667  35956.125667  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYN573SOHhxG",
    "outputId": "7f228183-abe3-4477-f574-3c9b25c62cd8"
   },
   "outputs": [],
   "source": [
    "list_indicators = ['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2zqII8rMIqn",
    "outputId": "1f54d044-e2d3-4a34-c041-e913d686654e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 1, State Space: 11\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(list_indicators)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "AWyp84Ltto19"
   },
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    \"hmax\": 100, \n",
    "    \"initial_amount\" : 1000,\n",
    "    \"num_stock_shares\": stock_dimension,\n",
    "    # buy and sell cost for each stock\n",
    "    \"buy_cost_pct\": [0.001] * stock_dimension,\n",
    "    \"sell_cost_pct\": [0.001] * stock_dimension,\n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"tech_indicator_list\": list_indicators, \n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 1e-4\n",
    "    \n",
    "}\n",
    "\n",
    "e_train_gym = StockTradingEnv(df = train, **env_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64EoqOrQjiVf"
   },
   "source": [
    "## Environment for Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xwSvvPjutpqS",
    "outputId": "deeaef07-afda-4ca1-fea8-99384224c7cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMNR5nHjh1iz"
   },
   "source": [
    "<a id='5'></a>\n",
    "# Part 6: Implement DRL Algorithms\n",
    "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
    "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
    "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
    "design their own DRL algorithms by adapting these DRL algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "364PsqckttcQ"
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDmqOyF9h1iz"
   },
   "source": [
    "### Model Training: 5 models, A2C DDPG, PPO, TD3, SAC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uijiWgkuh1jB"
   },
   "source": [
    "### Model 1: A2C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GUCnkn-HIbmj",
    "outputId": "a90a7a60-21a5-47e1-b683-1f7cbb4b8bc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_a2c = agent.get_model(\"a2c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0GVpkWGqH4-D",
    "outputId": "570d540f-abe9-402b-e0cc-f9b007228e8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 28        |\n",
      "|    iterations         | 100       |\n",
      "|    time_elapsed       | 17        |\n",
      "|    total_timesteps    | 500       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.5      |\n",
      "|    explained_variance | -1.23     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 99        |\n",
      "|    policy_loss        | -4.56e-05 |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 7.65e-09  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 28        |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 34        |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.57     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | -9.45e-05 |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 1.03e-08  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 28       |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.64    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 5.49e-05 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 8.21e-10 |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 28             |\n",
      "|    iterations         | 400            |\n",
      "|    time_elapsed       | 69             |\n",
      "|    total_timesteps    | 2000           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -1.71          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 399            |\n",
      "|    policy_loss        | 0.0027         |\n",
      "|    reward             | -5.6127654e-05 |\n",
      "|    std                | 1.34           |\n",
      "|    value_loss         | 4.27e-06       |\n",
      "------------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 28       |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.78    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 0.00268  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.43     |\n",
      "|    value_loss         | 3.16e-06 |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 28             |\n",
      "|    iterations         | 600            |\n",
      "|    time_elapsed       | 104            |\n",
      "|    total_timesteps    | 3000           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -1.85          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 599            |\n",
      "|    policy_loss        | 0.00331        |\n",
      "|    reward             | -2.7808283e-05 |\n",
      "|    std                | 1.53           |\n",
      "|    value_loss         | 2.59e-06       |\n",
      "------------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 28       |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.92    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 0.00203  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.65     |\n",
      "|    value_loss         | 7.69e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 28       |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.99    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 0.0012   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.77     |\n",
      "|    value_loss         | 5.47e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 28       |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 156      |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.06    |\n",
      "|    explained_variance | 2.38e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 0.0013   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.89     |\n",
      "|    value_loss         | 6.93e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 28       |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 174      |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.13    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 0.0015   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 2.03     |\n",
      "|    value_loss         | 8.03e-07 |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 28             |\n",
      "|    iterations         | 1100           |\n",
      "|    time_elapsed       | 191            |\n",
      "|    total_timesteps    | 5500           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -2.19          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1099           |\n",
      "|    policy_loss        | 0.00223        |\n",
      "|    reward             | -1.0007167e-05 |\n",
      "|    std                | 2.17           |\n",
      "|    value_loss         | 1.24e-06       |\n",
      "------------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 28       |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 209      |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.26    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 0.00235  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 2.33     |\n",
      "|    value_loss         | 1.18e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 28       |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 226      |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.33    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 0.0024   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 2.5      |\n",
      "|    value_loss         | 1.69e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 28       |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 243      |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.4     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 0.00403  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 2.68     |\n",
      "|    value_loss         | 1.71e-06 |\n",
      "------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 261          |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -2.47        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | 0.00249      |\n",
      "|    reward             | 4.560818e-07 |\n",
      "|    std                | 2.87         |\n",
      "|    value_loss         | 1.33e-06     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 28             |\n",
      "|    iterations         | 1600           |\n",
      "|    time_elapsed       | 278            |\n",
      "|    total_timesteps    | 8000           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -2.54          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1599           |\n",
      "|    policy_loss        | 0.00237        |\n",
      "|    reward             | -2.1477763e-06 |\n",
      "|    std                | 3.08           |\n",
      "|    value_loss         | 9.02e-07       |\n",
      "------------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 28       |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 295      |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.61    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 0.00174  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 3.3      |\n",
      "|    value_loss         | 7.26e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 28       |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 313      |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.68    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 0.00195  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 3.54     |\n",
      "|    value_loss         | 6.55e-07 |\n",
      "------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 28            |\n",
      "|    iterations         | 1900          |\n",
      "|    time_elapsed       | 330           |\n",
      "|    total_timesteps    | 9500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -2.75         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1899          |\n",
      "|    policy_loss        | 0.00173       |\n",
      "|    reward             | 7.0293464e-07 |\n",
      "|    std                | 3.8           |\n",
      "|    value_loss         | 5.53e-07      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 28             |\n",
      "|    iterations         | 2000           |\n",
      "|    time_elapsed       | 348            |\n",
      "|    total_timesteps    | 10000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -2.82          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1999           |\n",
      "|    policy_loss        | 0.00176        |\n",
      "|    reward             | -1.2422455e-06 |\n",
      "|    std                | 4.08           |\n",
      "|    value_loss         | 5.07e-07       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 28             |\n",
      "|    iterations         | 2100           |\n",
      "|    time_elapsed       | 365            |\n",
      "|    total_timesteps    | 10500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -2.89          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 2099           |\n",
      "|    policy_loss        | 0.00174        |\n",
      "|    reward             | -1.0046278e-06 |\n",
      "|    std                | 4.37           |\n",
      "|    value_loss         | 4.98e-07       |\n",
      "------------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 28       |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 382      |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.96    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 0.00176  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 4.69     |\n",
      "|    value_loss         | 5.17e-07 |\n",
      "------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 2300         |\n",
      "|    time_elapsed       | 400          |\n",
      "|    total_timesteps    | 11500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.03        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2299         |\n",
      "|    policy_loss        | 0.00169      |\n",
      "|    reward             | -5.88009e-07 |\n",
      "|    std                | 5.02         |\n",
      "|    value_loss         | 5.19e-07     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 28             |\n",
      "|    iterations         | 2400           |\n",
      "|    time_elapsed       | 417            |\n",
      "|    total_timesteps    | 12000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -3.1           |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 2399           |\n",
      "|    policy_loss        | 0.00208        |\n",
      "|    reward             | -2.1816929e-08 |\n",
      "|    std                | 5.39           |\n",
      "|    value_loss         | 4.92e-07       |\n",
      "------------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 28       |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 434      |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.17    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 0.00221  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 5.78     |\n",
      "|    value_loss         | 4.58e-07 |\n",
      "------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 28            |\n",
      "|    iterations         | 2600          |\n",
      "|    time_elapsed       | 451           |\n",
      "|    total_timesteps    | 13000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -3.24         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2599          |\n",
      "|    policy_loss        | 0.00177       |\n",
      "|    reward             | -2.847847e-07 |\n",
      "|    std                | 6.2           |\n",
      "|    value_loss         | 4.45e-07      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 28             |\n",
      "|    iterations         | 2700           |\n",
      "|    time_elapsed       | 468            |\n",
      "|    total_timesteps    | 13500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -3.31          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 2699           |\n",
      "|    policy_loss        | 0.00198        |\n",
      "|    reward             | -1.7573059e-07 |\n",
      "|    std                | 6.64           |\n",
      "|    value_loss         | 4.44e-07       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 28            |\n",
      "|    iterations         | 2800          |\n",
      "|    time_elapsed       | 485           |\n",
      "|    total_timesteps    | 14000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -3.38         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2799          |\n",
      "|    policy_loss        | 0.00217       |\n",
      "|    reward             | 1.3325142e-07 |\n",
      "|    std                | 7.12          |\n",
      "|    value_loss         | 4.48e-07      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 28             |\n",
      "|    iterations         | 2900           |\n",
      "|    time_elapsed       | 502            |\n",
      "|    total_timesteps    | 14500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -3.45          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 2899           |\n",
      "|    policy_loss        | 0.00242        |\n",
      "|    reward             | -1.7434465e-07 |\n",
      "|    std                | 7.64           |\n",
      "|    value_loss         | 4.39e-07       |\n",
      "------------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 28       |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 519      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.52    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 0.00187  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 8.19     |\n",
      "|    value_loss         | 4.29e-07 |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 28             |\n",
      "|    iterations         | 3100           |\n",
      "|    time_elapsed       | 536            |\n",
      "|    total_timesteps    | 15500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -3.59          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 3099           |\n",
      "|    policy_loss        | 0.00195        |\n",
      "|    reward             | -7.0073206e-08 |\n",
      "|    std                | 8.79           |\n",
      "|    value_loss         | 4.2e-07        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 28            |\n",
      "|    iterations         | 3200          |\n",
      "|    time_elapsed       | 553           |\n",
      "|    total_timesteps    | 16000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -3.66         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3199          |\n",
      "|    policy_loss        | 0.00205       |\n",
      "|    reward             | -4.497855e-11 |\n",
      "|    std                | 9.42          |\n",
      "|    value_loss         | 4.13e-07      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 3300         |\n",
      "|    time_elapsed       | 570          |\n",
      "|    total_timesteps    | 16500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.73        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3299         |\n",
      "|    policy_loss        | 0.00228      |\n",
      "|    reward             | 6.775297e-09 |\n",
      "|    std                | 10.1         |\n",
      "|    value_loss         | 4.07e-07     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 3400         |\n",
      "|    time_elapsed       | 587          |\n",
      "|    total_timesteps    | 17000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.8         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3399         |\n",
      "|    policy_loss        | 0.0024       |\n",
      "|    reward             | -5.43131e-08 |\n",
      "|    std                | 10.8         |\n",
      "|    value_loss         | 4.03e-07     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 28             |\n",
      "|    iterations         | 3500           |\n",
      "|    time_elapsed       | 603            |\n",
      "|    total_timesteps    | 17500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -3.87          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 3499           |\n",
      "|    policy_loss        | 0.00227        |\n",
      "|    reward             | -4.0272088e-08 |\n",
      "|    std                | 11.6           |\n",
      "|    value_loss         | 3.97e-07       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 28             |\n",
      "|    iterations         | 3600           |\n",
      "|    time_elapsed       | 620            |\n",
      "|    total_timesteps    | 18000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -3.94          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 3599           |\n",
      "|    policy_loss        | 0.00208        |\n",
      "|    reward             | -2.3747823e-08 |\n",
      "|    std                | 12.5           |\n",
      "|    value_loss         | 3.94e-07       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 29            |\n",
      "|    iterations         | 3700          |\n",
      "|    time_elapsed       | 637           |\n",
      "|    total_timesteps    | 18500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.01         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3699          |\n",
      "|    policy_loss        | 0.00212       |\n",
      "|    reward             | 3.3083316e-09 |\n",
      "|    std                | 13.4          |\n",
      "|    value_loss         | 3.86e-07      |\n",
      "-----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 29       |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 654      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.08    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 0.00211  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 14.3     |\n",
      "|    value_loss         | 3.84e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 29       |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 671      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.15    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 0.00214  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 15.4     |\n",
      "|    value_loss         | 3.79e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 29       |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 688      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.22    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 0.00306  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 16.5     |\n",
      "|    value_loss         | 3.75e-07 |\n",
      "------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 29            |\n",
      "|    iterations         | 4100          |\n",
      "|    time_elapsed       | 705           |\n",
      "|    total_timesteps    | 20500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.29         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4099          |\n",
      "|    policy_loss        | 0.00249       |\n",
      "|    reward             | -5.492129e-09 |\n",
      "|    std                | 17.7          |\n",
      "|    value_loss         | 3.72e-07      |\n",
      "-----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 29       |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 722      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.36    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 0.0024   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 19       |\n",
      "|    value_loss         | 3.68e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 29       |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 739      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.43    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 0.0025   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 20.3     |\n",
      "|    value_loss         | 3.62e-07 |\n",
      "------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 29            |\n",
      "|    iterations         | 4400          |\n",
      "|    time_elapsed       | 756           |\n",
      "|    total_timesteps    | 22000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.5          |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4399          |\n",
      "|    policy_loss        | 0.00258       |\n",
      "|    reward             | -3.262929e-09 |\n",
      "|    std                | 21.8          |\n",
      "|    value_loss         | 3.59e-07      |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 29        |\n",
      "|    iterations         | 4500      |\n",
      "|    time_elapsed       | 773       |\n",
      "|    total_timesteps    | 22500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.57     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4499      |\n",
      "|    policy_loss        | 0.00243   |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 23.4      |\n",
      "|    value_loss         | 3.55e-07  |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 29             |\n",
      "|    iterations         | 4600           |\n",
      "|    time_elapsed       | 791            |\n",
      "|    total_timesteps    | 23000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -4.64          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 4599           |\n",
      "|    policy_loss        | 0.0026         |\n",
      "|    reward             | -4.9407567e-10 |\n",
      "|    std                | 25.1           |\n",
      "|    value_loss         | 3.52e-07       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 29            |\n",
      "|    iterations         | 4700          |\n",
      "|    time_elapsed       | 808           |\n",
      "|    total_timesteps    | 23500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.71         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4699          |\n",
      "|    policy_loss        | 0.00237       |\n",
      "|    reward             | -2.542214e-09 |\n",
      "|    std                | 26.9          |\n",
      "|    value_loss         | 3.5e-07       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 29            |\n",
      "|    iterations         | 4800          |\n",
      "|    time_elapsed       | 825           |\n",
      "|    total_timesteps    | 24000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.78         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4799          |\n",
      "|    policy_loss        | 0.0024        |\n",
      "|    reward             | -1.669556e-09 |\n",
      "|    std                | 28.8          |\n",
      "|    value_loss         | 3.46e-07      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 28            |\n",
      "|    iterations         | 4900          |\n",
      "|    time_elapsed       | 873           |\n",
      "|    total_timesteps    | 24500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.85         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4899          |\n",
      "|    policy_loss        | 0.00238       |\n",
      "|    reward             | -9.844502e-10 |\n",
      "|    std                | 30.9          |\n",
      "|    value_loss         | 3.45e-07      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 26            |\n",
      "|    iterations         | 5000          |\n",
      "|    time_elapsed       | 931           |\n",
      "|    total_timesteps    | 25000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.92         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4999          |\n",
      "|    policy_loss        | 0.0025        |\n",
      "|    reward             | -7.692528e-10 |\n",
      "|    std                | 33.2          |\n",
      "|    value_loss         | 3.43e-07      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 26            |\n",
      "|    iterations         | 5100          |\n",
      "|    time_elapsed       | 950           |\n",
      "|    total_timesteps    | 25500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.99         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5099          |\n",
      "|    policy_loss        | 0.00242       |\n",
      "|    reward             | -6.161946e-10 |\n",
      "|    std                | 35.6          |\n",
      "|    value_loss         | 3.4e-07       |\n",
      "-----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 26       |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 969      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.06    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 0.0026   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 38.1     |\n",
      "|    value_loss         | 3.39e-07 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 26        |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 1012      |\n",
      "|    total_timesteps    | 26500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.13     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | 0.00261   |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 40.9      |\n",
      "|    value_loss         | 3.38e-07  |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 26             |\n",
      "|    iterations         | 5400           |\n",
      "|    time_elapsed       | 1029           |\n",
      "|    total_timesteps    | 27000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -5.2           |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 5399           |\n",
      "|    policy_loss        | -2.74e-07      |\n",
      "|    reward             | -2.9322894e-10 |\n",
      "|    std                | 43.8           |\n",
      "|    value_loss         | 5.6e-15        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 26            |\n",
      "|    iterations         | 5500          |\n",
      "|    time_elapsed       | 1046          |\n",
      "|    total_timesteps    | 27500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -5.27         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5499          |\n",
      "|    policy_loss        | -2.09e-07     |\n",
      "|    reward             | -3.420091e-10 |\n",
      "|    std                | 47            |\n",
      "|    value_loss         | 2.22e-15      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 25             |\n",
      "|    iterations         | 5600           |\n",
      "|    time_elapsed       | 1088           |\n",
      "|    total_timesteps    | 28000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -5.34          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 5599           |\n",
      "|    policy_loss        | -4.67e-10      |\n",
      "|    reward             | -1.7734805e-10 |\n",
      "|    std                | 50.4           |\n",
      "|    value_loss         | 9.59e-21       |\n",
      "------------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 25       |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 1105     |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.41    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 6.02e-11 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 54       |\n",
      "|    value_loss         | 3.79e-21 |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 25             |\n",
      "|    iterations         | 5800           |\n",
      "|    time_elapsed       | 1122           |\n",
      "|    total_timesteps    | 29000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -5.48          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 5799           |\n",
      "|    policy_loss        | 7.88e-10       |\n",
      "|    reward             | -1.0818573e-10 |\n",
      "|    std                | 57.9           |\n",
      "|    value_loss         | 1.94e-20       |\n",
      "------------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 25       |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 1165     |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.55    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 0.000369 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 62.2     |\n",
      "|    value_loss         | 4.95e-09 |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 25             |\n",
      "|    iterations         | 6000           |\n",
      "|    time_elapsed       | 1181           |\n",
      "|    total_timesteps    | 30000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -5.62          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 5999           |\n",
      "|    policy_loss        | -3.06e-05      |\n",
      "|    reward             | -6.6615866e-11 |\n",
      "|    std                | 66.6           |\n",
      "|    value_loss         | 4.02e-11       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 25            |\n",
      "|    iterations         | 6100          |\n",
      "|    time_elapsed       | 1199          |\n",
      "|    total_timesteps    | 30500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -5.69         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6099          |\n",
      "|    policy_loss        | -0.00548      |\n",
      "|    reward             | -4.342322e-11 |\n",
      "|    std                | 71.4          |\n",
      "|    value_loss         | 1.13e-06      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 24             |\n",
      "|    iterations         | 6200           |\n",
      "|    time_elapsed       | 1241           |\n",
      "|    total_timesteps    | 31000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -5.76          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 6199           |\n",
      "|    policy_loss        | -0.00126       |\n",
      "|    reward             | -1.7467682e-11 |\n",
      "|    std                | 76.6           |\n",
      "|    value_loss         | 6.58e-08       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 25             |\n",
      "|    iterations         | 6300           |\n",
      "|    time_elapsed       | 1258           |\n",
      "|    total_timesteps    | 31500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -5.83          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 6299           |\n",
      "|    policy_loss        | -0.00174       |\n",
      "|    reward             | -3.2109197e-11 |\n",
      "|    std                | 82.2           |\n",
      "|    value_loss         | 9.76e-08       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 25            |\n",
      "|    iterations         | 6400          |\n",
      "|    time_elapsed       | 1275          |\n",
      "|    total_timesteps    | 32000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -5.9          |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6399          |\n",
      "|    policy_loss        | -0.00244      |\n",
      "|    reward             | -2.981053e-11 |\n",
      "|    std                | 88.1          |\n",
      "|    value_loss         | 2.35e-07      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 24             |\n",
      "|    iterations         | 6500           |\n",
      "|    time_elapsed       | 1317           |\n",
      "|    total_timesteps    | 32500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -5.97          |\n",
      "|    explained_variance | 5.96e-08       |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 6499           |\n",
      "|    policy_loss        | -0.00466       |\n",
      "|    reward             | -2.8847733e-11 |\n",
      "|    std                | 94.5           |\n",
      "|    value_loss         | 4.52e-07       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 24            |\n",
      "|    iterations         | 6600          |\n",
      "|    time_elapsed       | 1334          |\n",
      "|    total_timesteps    | 33000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.04         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6599          |\n",
      "|    policy_loss        | -0.00404      |\n",
      "|    reward             | 5.5705583e-12 |\n",
      "|    std                | 101           |\n",
      "|    value_loss         | 5.07e-07      |\n",
      "-----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 24       |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 1376     |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.11    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | -0.00333 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 109      |\n",
      "|    value_loss         | 3.97e-07 |\n",
      "------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 24            |\n",
      "|    iterations         | 6800          |\n",
      "|    time_elapsed       | 1393          |\n",
      "|    total_timesteps    | 34000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.18         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6799          |\n",
      "|    policy_loss        | -0.00315      |\n",
      "|    reward             | -8.079474e-12 |\n",
      "|    std                | 117           |\n",
      "|    value_loss         | 3.27e-07      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 24             |\n",
      "|    iterations         | 6900           |\n",
      "|    time_elapsed       | 1410           |\n",
      "|    total_timesteps    | 34500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -6.25          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 6899           |\n",
      "|    policy_loss        | -0.0034        |\n",
      "|    reward             | -6.8590077e-12 |\n",
      "|    std                | 125            |\n",
      "|    value_loss         | 3.2e-07        |\n",
      "------------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 24       |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 1452     |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.32    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | -0.00313 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 134      |\n",
      "|    value_loss         | 3.4e-07  |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 24             |\n",
      "|    iterations         | 7100           |\n",
      "|    time_elapsed       | 1469           |\n",
      "|    total_timesteps    | 35500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -6.39          |\n",
      "|    explained_variance | 1.19e-07       |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 7099           |\n",
      "|    policy_loss        | -0.00334       |\n",
      "|    reward             | -4.0527616e-12 |\n",
      "|    std                | 144            |\n",
      "|    value_loss         | 3.51e-07       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 24             |\n",
      "|    iterations         | 7200           |\n",
      "|    time_elapsed       | 1486           |\n",
      "|    total_timesteps    | 36000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -6.46          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 7199           |\n",
      "|    policy_loss        | -0.00337       |\n",
      "|    reward             | -1.1084853e-11 |\n",
      "|    std                | 154            |\n",
      "|    value_loss         | 3.47e-07       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 7300           |\n",
      "|    time_elapsed       | 1528           |\n",
      "|    total_timesteps    | 36500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -6.53          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 7299           |\n",
      "|    policy_loss        | -0.00367       |\n",
      "|    reward             | -2.5242837e-12 |\n",
      "|    std                | 165            |\n",
      "|    value_loss         | 3.38e-07       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 7400           |\n",
      "|    time_elapsed       | 1545           |\n",
      "|    total_timesteps    | 37000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -6.6           |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 7399           |\n",
      "|    policy_loss        | -0.00331       |\n",
      "|    reward             | -1.9522448e-12 |\n",
      "|    std                | 177            |\n",
      "|    value_loss         | 3.34e-07       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 7500           |\n",
      "|    time_elapsed       | 1562           |\n",
      "|    total_timesteps    | 37500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -6.67          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 7499           |\n",
      "|    policy_loss        | -0.00328       |\n",
      "|    reward             | -1.5147262e-12 |\n",
      "|    std                | 190            |\n",
      "|    value_loss         | 3.33e-07       |\n",
      "------------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 1605     |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.74    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | -0.00349 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 204      |\n",
      "|    value_loss         | 3.33e-07 |\n",
      "------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 7700          |\n",
      "|    time_elapsed       | 1622          |\n",
      "|    total_timesteps    | 38500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.81         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7699          |\n",
      "|    policy_loss        | -0.00365      |\n",
      "|    reward             | 1.1406587e-13 |\n",
      "|    std                | 219           |\n",
      "|    value_loss         | 3.32e-07      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 7800          |\n",
      "|    time_elapsed       | 1664          |\n",
      "|    total_timesteps    | 39000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.88         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7799          |\n",
      "|    policy_loss        | -0.00386      |\n",
      "|    reward             | 8.3388564e-13 |\n",
      "|    std                | 234           |\n",
      "|    value_loss         | 3.32e-07      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 7900          |\n",
      "|    time_elapsed       | 1681          |\n",
      "|    total_timesteps    | 39500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.95         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7899          |\n",
      "|    policy_loss        | -0.00348      |\n",
      "|    reward             | 2.9842234e-13 |\n",
      "|    std                | 251           |\n",
      "|    value_loss         | 3.31e-07      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 8000          |\n",
      "|    time_elapsed       | 1698          |\n",
      "|    total_timesteps    | 40000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -7.02         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7999          |\n",
      "|    policy_loss        | -0.00379      |\n",
      "|    reward             | -4.385457e-13 |\n",
      "|    std                | 270           |\n",
      "|    value_loss         | 3.29e-07      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 8100          |\n",
      "|    time_elapsed       | 1740          |\n",
      "|    total_timesteps    | 40500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -7.09         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8099          |\n",
      "|    policy_loss        | -0.00361      |\n",
      "|    reward             | 3.9167584e-13 |\n",
      "|    std                | 289           |\n",
      "|    value_loss         | 3.29e-07      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 8200           |\n",
      "|    time_elapsed       | 1757           |\n",
      "|    total_timesteps    | 41000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -7.15          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 8199           |\n",
      "|    policy_loss        | -0.00364       |\n",
      "|    reward             | -6.3645763e-13 |\n",
      "|    std                | 310            |\n",
      "|    value_loss         | 3.29e-07       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 8300          |\n",
      "|    time_elapsed       | 1775          |\n",
      "|    total_timesteps    | 41500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -7.22         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8299          |\n",
      "|    policy_loss        | -0.00365      |\n",
      "|    reward             | -2.139021e-13 |\n",
      "|    std                | 333           |\n",
      "|    value_loss         | 3.29e-07      |\n",
      "-----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 1817     |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.29    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | -0.00363 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 357      |\n",
      "|    value_loss         | 3.29e-07 |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 8500           |\n",
      "|    time_elapsed       | 1834           |\n",
      "|    total_timesteps    | 42500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -7.36          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 8499           |\n",
      "|    policy_loss        | -0.00367       |\n",
      "|    reward             | -1.3041457e-13 |\n",
      "|    std                | 382            |\n",
      "|    value_loss         | 3.27e-07       |\n",
      "------------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 1851     |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.43    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | -0.00396 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 410      |\n",
      "|    value_loss         | 3.28e-07 |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 8700           |\n",
      "|    time_elapsed       | 1868           |\n",
      "|    total_timesteps    | 43500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -7.5           |\n",
      "|    explained_variance | 1.19e-07       |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 8699           |\n",
      "|    policy_loss        | -0.00395       |\n",
      "|    reward             | -2.7027556e-14 |\n",
      "|    std                | 440            |\n",
      "|    value_loss         | 3.27e-07       |\n",
      "------------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 1885     |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.57    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | -0.0045  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 471      |\n",
      "|    value_loss         | 3.26e-07 |\n",
      "------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 8900          |\n",
      "|    time_elapsed       | 1902          |\n",
      "|    total_timesteps    | 44500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -7.64         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8899          |\n",
      "|    policy_loss        | -0.00404      |\n",
      "|    reward             | 2.5177746e-14 |\n",
      "|    std                | 506           |\n",
      "|    value_loss         | 3.26e-07      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 23           |\n",
      "|    iterations         | 9000         |\n",
      "|    time_elapsed       | 1919         |\n",
      "|    total_timesteps    | 45000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.71        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8999         |\n",
      "|    policy_loss        | -0.0038      |\n",
      "|    reward             | -3.49835e-14 |\n",
      "|    std                | 542          |\n",
      "|    value_loss         | 3.25e-07     |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 1937      |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.78     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | -0.00385  |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 582       |\n",
      "|    value_loss         | 3.25e-07  |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 9200          |\n",
      "|    time_elapsed       | 1956          |\n",
      "|    total_timesteps    | 46000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -7.85         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9199          |\n",
      "|    policy_loss        | -0.00393      |\n",
      "|    reward             | 1.6396923e-14 |\n",
      "|    std                | 624           |\n",
      "|    value_loss         | 3.25e-07      |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 9300      |\n",
      "|    time_elapsed       | 2003      |\n",
      "|    total_timesteps    | 46500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.92     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9299      |\n",
      "|    policy_loss        | -0.00385  |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 669       |\n",
      "|    value_loss         | 3.25e-07  |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 22             |\n",
      "|    iterations         | 9400           |\n",
      "|    time_elapsed       | 2063           |\n",
      "|    total_timesteps    | 47000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -7.99          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 9399           |\n",
      "|    policy_loss        | -0.00394       |\n",
      "|    reward             | -1.4294562e-14 |\n",
      "|    std                | 717            |\n",
      "|    value_loss         | 3.25e-07       |\n",
      "------------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 22       |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 2082     |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.06    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | -0.00404 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 769      |\n",
      "|    value_loss         | 3.23e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 22       |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 2102     |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.13    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | -0.00399 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 825      |\n",
      "|    value_loss         | 3.23e-07 |\n",
      "------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 22            |\n",
      "|    iterations         | 9700          |\n",
      "|    time_elapsed       | 2145          |\n",
      "|    total_timesteps    | 48500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -8.2          |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9699          |\n",
      "|    policy_loss        | -0.00407      |\n",
      "|    reward             | 2.0731189e-15 |\n",
      "|    std                | 885           |\n",
      "|    value_loss         | 3.23e-07      |\n",
      "-----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 22       |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 2162     |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.27    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | -0.00436 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 948      |\n",
      "|    value_loss         | 3.23e-07 |\n",
      "------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 22            |\n",
      "|    iterations         | 9900          |\n",
      "|    time_elapsed       | 2179          |\n",
      "|    total_timesteps    | 49500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -8.34         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9899          |\n",
      "|    policy_loss        | -0.00407      |\n",
      "|    reward             | 9.3194515e-17 |\n",
      "|    std                | 1.02e+03      |\n",
      "|    value_loss         | 3.23e-07      |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 22        |\n",
      "|    iterations         | 10000     |\n",
      "|    time_elapsed       | 2221      |\n",
      "|    total_timesteps    | 50000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.41     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9999      |\n",
      "|    policy_loss        | -0.00434  |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 1.09e+03  |\n",
      "|    value_loss         | 3.22e-07  |\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                             tb_log_name='a2c',\n",
    "                             total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_path_export_model_a2c = '../models/finrl_stocktrading_neurips_2018_mod_a2c.pkl'\n",
    "\n",
    "# # Open a file and use dump()\n",
    "# with open(full_path_export_model_a2c, 'wb') as file:\n",
    "      \n",
    "#     # A new file will be created\n",
    "#     pickle.dump(trained_a2c, file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRiOtrywfAo1"
   },
   "source": [
    "### Model 2: DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "M2YadjfnLwgt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_ddpg = agent.get_model(\"ddpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "tCDa78rqfO_a",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "trained_ddpg = agent.train_model(model=model_ddpg, \n",
    "                             tb_log_name='ddpg',\n",
    "                             total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_path_export_model_ddpg = '../models/finrl_stocktrading_neurips_2018_mod_ddpg.pkl'\n",
    "\n",
    "# # Open a file and use dump()\n",
    "# with open(full_path_export_model_ddpg, 'wb') as file:\n",
    "      \n",
    "#     # A new file will be created\n",
    "#     pickle.dump(trained_ddpg, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_gDkU-j-fCmZ"
   },
   "source": [
    "### Model 3: PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "y5D5PFUhMzSV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "Gt8eIQKYM4G3",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 21   |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 95   |\n",
      "|    total_timesteps | 2048 |\n",
      "| train/             |      |\n",
      "|    reward          | 0.0  |\n",
      "-----------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 18             |\n",
      "|    iterations           | 2              |\n",
      "|    time_elapsed         | 217            |\n",
      "|    total_timesteps      | 4096           |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0008110906   |\n",
      "|    clip_fraction        | 0.000391       |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.42          |\n",
      "|    explained_variance   | -1.19e-07      |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.0134        |\n",
      "|    n_updates            | 10             |\n",
      "|    policy_gradient_loss | 3.75e-05       |\n",
      "|    reward               | -1.3225344e-05 |\n",
      "|    std                  | 0.996          |\n",
      "|    value_loss           | 7.23e-05       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 19             |\n",
      "|    iterations           | 3              |\n",
      "|    time_elapsed         | 313            |\n",
      "|    total_timesteps      | 6144           |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0035328288   |\n",
      "|    clip_fraction        | 0.036          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.41          |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.0129        |\n",
      "|    n_updates            | 20             |\n",
      "|    policy_gradient_loss | -0.00185       |\n",
      "|    reward               | -3.3328693e-06 |\n",
      "|    std                  | 0.995          |\n",
      "|    value_loss           | 2.03e-05       |\n",
      "--------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 18           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 434          |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015249271 |\n",
      "|    clip_fraction        | 0.0173       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0101      |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -2.71e-05    |\n",
      "|    reward               | 0.0          |\n",
      "|    std                  | 0.995        |\n",
      "|    value_loss           | 2.48e-05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 530          |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.001917196  |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00919     |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.000401    |\n",
      "|    reward               | -7.17692e-07 |\n",
      "|    std                  | 0.995        |\n",
      "|    value_loss           | 9.2e-06      |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 18             |\n",
      "|    iterations           | 6              |\n",
      "|    time_elapsed         | 652            |\n",
      "|    total_timesteps      | 12288          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0068314173   |\n",
      "|    clip_fraction        | 0.0432         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.42          |\n",
      "|    explained_variance   | -1.19e-07      |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.00585       |\n",
      "|    n_updates            | 50             |\n",
      "|    policy_gradient_loss | -0.00121       |\n",
      "|    reward               | -4.1044803e-08 |\n",
      "|    std                  | 0.998          |\n",
      "|    value_loss           | 1.88e-05       |\n",
      "--------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 748          |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052418727 |\n",
      "|    clip_fraction        | 0.0375       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.000319    |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    reward               | 0.0          |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 5.77e-06     |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 16             |\n",
      "|    iterations           | 8              |\n",
      "|    time_elapsed         | 979            |\n",
      "|    total_timesteps      | 16384          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0031131827   |\n",
      "|    clip_fraction        | 0.00151        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.42          |\n",
      "|    explained_variance   | 5.96e-08       |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.0128        |\n",
      "|    n_updates            | 70             |\n",
      "|    policy_gradient_loss | -0.000284      |\n",
      "|    reward               | -3.7329578e-08 |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 4.93e-06       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 17             |\n",
      "|    iterations           | 9              |\n",
      "|    time_elapsed         | 1051           |\n",
      "|    total_timesteps      | 18432          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 7.402178e-05   |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.42          |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.0138        |\n",
      "|    n_updates            | 80             |\n",
      "|    policy_gradient_loss | 0.000107       |\n",
      "|    reward               | -1.4282393e-08 |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 3.11e-06       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 17            |\n",
      "|    iterations           | 10            |\n",
      "|    time_elapsed         | 1172          |\n",
      "|    total_timesteps      | 20480         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.007078069   |\n",
      "|    clip_fraction        | 0.0398        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.41         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.0127       |\n",
      "|    n_updates            | 90            |\n",
      "|    policy_gradient_loss | -0.00129      |\n",
      "|    reward               | 2.0052264e-09 |\n",
      "|    std                  | 0.987         |\n",
      "|    value_loss           | 5.92e-06      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 17             |\n",
      "|    iterations           | 11             |\n",
      "|    time_elapsed         | 1263           |\n",
      "|    total_timesteps      | 22528          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0020228303   |\n",
      "|    clip_fraction        | 0.004          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.4           |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.0115        |\n",
      "|    n_updates            | 100            |\n",
      "|    policy_gradient_loss | 0.000152       |\n",
      "|    reward               | -1.9089585e-09 |\n",
      "|    std                  | 0.976          |\n",
      "|    value_loss           | 2.31e-06       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 17            |\n",
      "|    iterations           | 12            |\n",
      "|    time_elapsed         | 1384          |\n",
      "|    total_timesteps      | 24576         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0033917162  |\n",
      "|    clip_fraction        | 0.0137        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.39         |\n",
      "|    explained_variance   | 1.79e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.0076       |\n",
      "|    n_updates            | 110           |\n",
      "|    policy_gradient_loss | -0.000659     |\n",
      "|    reward               | -9.458091e-10 |\n",
      "|    std                  | 0.969         |\n",
      "|    value_loss           | 7.2e-06       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 17           |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 1480         |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023446959 |\n",
      "|    clip_fraction        | 0.002        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00213     |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00017     |\n",
      "|    reward               | 0.0          |\n",
      "|    std                  | 0.969        |\n",
      "|    value_loss           | 1.1e-06      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 17           |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 1601         |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061500664 |\n",
      "|    clip_fraction        | 0.099        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0114      |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00112     |\n",
      "|    reward               | 6.541209e-11 |\n",
      "|    std                  | 0.965        |\n",
      "|    value_loss           | 1.5e-06      |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 18             |\n",
      "|    iterations           | 15             |\n",
      "|    time_elapsed         | 1677           |\n",
      "|    total_timesteps      | 30720          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0051346296   |\n",
      "|    clip_fraction        | 0.0479         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.38          |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.0273        |\n",
      "|    n_updates            | 140            |\n",
      "|    policy_gradient_loss | -0.00211       |\n",
      "|    reward               | -3.1770395e-11 |\n",
      "|    std                  | 0.967          |\n",
      "|    value_loss           | 5.03e-07       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 18             |\n",
      "|    iterations           | 16             |\n",
      "|    time_elapsed         | 1798           |\n",
      "|    total_timesteps      | 32768          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0047731698   |\n",
      "|    clip_fraction        | 0.0266         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.38          |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.0172        |\n",
      "|    n_updates            | 150            |\n",
      "|    policy_gradient_loss | -0.000461      |\n",
      "|    reward               | -2.3881847e-12 |\n",
      "|    std                  | 0.961          |\n",
      "|    value_loss           | 8.99e-07       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 18             |\n",
      "|    iterations           | 17             |\n",
      "|    time_elapsed         | 1894           |\n",
      "|    total_timesteps      | 34816          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.003081656    |\n",
      "|    clip_fraction        | 0.00933        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.38          |\n",
      "|    explained_variance   | -1.19e-07      |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.0156        |\n",
      "|    n_updates            | 160            |\n",
      "|    policy_gradient_loss | -0.000771      |\n",
      "|    reward               | -6.2858148e-12 |\n",
      "|    std                  | 0.955          |\n",
      "|    value_loss           | 6.76e-06       |\n",
      "--------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 18           |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 2015         |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.047433e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.37        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0137      |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | 0.000382     |\n",
      "|    reward               | 4.900153e-13 |\n",
      "|    std                  | 0.956        |\n",
      "|    value_loss           | 1.61e-07     |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 18             |\n",
      "|    iterations           | 19             |\n",
      "|    time_elapsed         | 2111           |\n",
      "|    total_timesteps      | 38912          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.00076471415  |\n",
      "|    clip_fraction        | 0.00967        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.37          |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.0135        |\n",
      "|    n_updates            | 180            |\n",
      "|    policy_gradient_loss | -0.00026       |\n",
      "|    reward               | -8.0310785e-13 |\n",
      "|    std                  | 0.943          |\n",
      "|    value_loss           | 8.64e-06       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 18            |\n",
      "|    iterations           | 20            |\n",
      "|    time_elapsed         | 2232          |\n",
      "|    total_timesteps      | 40960         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0020195274  |\n",
      "|    clip_fraction        | 0.00493       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.35         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.0136       |\n",
      "|    n_updates            | 190           |\n",
      "|    policy_gradient_loss | -0.000272     |\n",
      "|    reward               | 6.2814615e-14 |\n",
      "|    std                  | 0.925         |\n",
      "|    value_loss           | 3.86e-07      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 18             |\n",
      "|    iterations           | 21             |\n",
      "|    time_elapsed         | 2328           |\n",
      "|    total_timesteps      | 43008          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0011006143   |\n",
      "|    clip_fraction        | 0.00469        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.34          |\n",
      "|    explained_variance   | 1.19e-07       |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.0133        |\n",
      "|    n_updates            | 200            |\n",
      "|    policy_gradient_loss | -4.04e-05      |\n",
      "|    reward               | -1.6626343e-13 |\n",
      "|    std                  | 0.917          |\n",
      "|    value_loss           | 4.49e-05       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 18            |\n",
      "|    iterations           | 22            |\n",
      "|    time_elapsed         | 2428          |\n",
      "|    total_timesteps      | 45056         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0048123654  |\n",
      "|    clip_fraction        | 0.00884       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.33         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.00811      |\n",
      "|    n_updates            | 210           |\n",
      "|    policy_gradient_loss | 0.000178      |\n",
      "|    reward               | -8.236957e-14 |\n",
      "|    std                  | 0.918         |\n",
      "|    value_loss           | 5.94e-08      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 18            |\n",
      "|    iterations           | 23            |\n",
      "|    time_elapsed         | 2580          |\n",
      "|    total_timesteps      | 47104         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.009231642   |\n",
      "|    clip_fraction        | 0.0627        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.34         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.0302       |\n",
      "|    n_updates            | 220           |\n",
      "|    policy_gradient_loss | -0.00128      |\n",
      "|    reward               | -4.724219e-15 |\n",
      "|    std                  | 0.935         |\n",
      "|    value_loss           | 4.23e-09      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 13            |\n",
      "|    iterations           | 24            |\n",
      "|    time_elapsed         | 3549          |\n",
      "|    total_timesteps      | 49152         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0037289578  |\n",
      "|    clip_fraction        | 0.0193        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.36         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.0163       |\n",
      "|    n_updates            | 230           |\n",
      "|    policy_gradient_loss | -0.00055      |\n",
      "|    reward               | -4.732272e-15 |\n",
      "|    std                  | 0.949         |\n",
      "|    value_loss           | 1.45e-09      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 14             |\n",
      "|    iterations           | 25             |\n",
      "|    time_elapsed         | 3645           |\n",
      "|    total_timesteps      | 51200          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0024661408   |\n",
      "|    clip_fraction        | 0.000537       |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.37          |\n",
      "|    explained_variance   | -1.19e-07      |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.0162        |\n",
      "|    n_updates            | 240            |\n",
      "|    policy_gradient_loss | 5.66e-05       |\n",
      "|    reward               | -4.2886955e-15 |\n",
      "|    std                  | 0.948          |\n",
      "|    value_loss           | 2e-09          |\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_ppo = agent.train_model(model=model_ppo, \n",
    "                             tb_log_name='ppo',\n",
    "                             total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Zpv4S0-fDBv"
   },
   "source": [
    "### Model 4: TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "JSAHhV4Xc-bh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "TD3_PARAMS = {\"batch_size\": 100, \n",
    "              \"buffer_size\": 1000000, \n",
    "              \"learning_rate\": 0.001}\n",
    "\n",
    "model_td3 = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "OSRxNYAxdKpU"
   },
   "outputs": [],
   "source": [
    "trained_td3 = agent.train_model(model=model_td3, \n",
    "                             tb_log_name='td3',\n",
    "                             total_timesteps=30000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dr49PotrfG01"
   },
   "source": [
    "### Model 5: SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "xwOhVjqRkCdM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 1000000, 'learning_rate': 0.0001, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "SAC_PARAMS = {\n",
    "    \"batch_size\": 128,\n",
    "    \"buffer_size\": 1000000,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"learning_starts\": 100,\n",
    "    \"ent_coef\": \"auto_0.1\",\n",
    "}\n",
    "\n",
    "model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "K8RSdKCckJyH"
   },
   "outputs": [],
   "source": [
    "trained_sac = agent.train_model(model=model_sac, \n",
    "                             tb_log_name='sac',\n",
    "                             total_timesteps=60000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2wZgkQXh1jE"
   },
   "source": [
    "## Trading\n",
    "Assume that we have $1,000 initial capital at 2021-06-30. We use the DDPG model to trade Dow jones 30 stocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bEv5KGC8h1jE"
   },
   "source": [
    "### Set turbulence threshold\n",
    "Set the turbulence threshold to be greater than the maximum of insample turbulence data, if current turbulence index is greater than the threshold, then we assume that the current market is volatile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "efwBi84ch1jE"
   },
   "outputs": [],
   "source": [
    "data_risk_indicator = processed[(processed.date<'2021-07-01') & (processed.date>='2020-01-01')]\n",
    "insample_risk_indicator = data_risk_indicator.drop_duplicates(subset=['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5mmgQF_h1jQ"
   },
   "source": [
    "### Trade\n",
    "\n",
    "DRL model needs to update periodically in order to take full advantage of the data, ideally we need to retrain our model yearly, quarterly, or monthly. We also need to tune the parameters along the way, in this notebook I only use the in-sample data from 2009-01 to 2020-07 to tune the parameters once, so there is some alpha decay here as the length of trade date extends. \n",
    "\n",
    "Numerous hyperparameters – e.g. the learning rate, the total number of samples to train on – influence the learning process and are usually determined by testing some variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "cIqoV0GSI52v"
   },
   "outputs": [],
   "source": [
    "# e_trade_gym = StockTradingEnv(df = trade, turbulence_threshold = 70,risk_indicator_col='vix', **env_kwargs)\n",
    "e_trade_gym = StockTradingEnv(df = trade, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "W_XNgGsBMeVw"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>upper_shadow</th>\n",
       "      <th>lower_shadow</th>\n",
       "      <th>real_body</th>\n",
       "      <th>...</th>\n",
       "      <th>CDLEVENINGSTAR_NEW</th>\n",
       "      <th>CDLENGULFINGBEARISH_NEW</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-06-30 00:00:00</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>35911.72</td>\n",
       "      <td>35941.75</td>\n",
       "      <td>35868.84</td>\n",
       "      <td>35924.04</td>\n",
       "      <td>60.951928</td>\n",
       "      <td>17.71</td>\n",
       "      <td>42.88</td>\n",
       "      <td>12.32</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-24.813872</td>\n",
       "      <td>36016.914824</td>\n",
       "      <td>35811.410176</td>\n",
       "      <td>47.891159</td>\n",
       "      <td>-47.501402</td>\n",
       "      <td>25.261039</td>\n",
       "      <td>35965.887000</td>\n",
       "      <td>35959.781500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-30 00:01:00</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>35924.03</td>\n",
       "      <td>35971.25</td>\n",
       "      <td>35850.00</td>\n",
       "      <td>35901.60</td>\n",
       "      <td>49.714898</td>\n",
       "      <td>47.22</td>\n",
       "      <td>51.60</td>\n",
       "      <td>22.43</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-23.061153</td>\n",
       "      <td>36008.122908</td>\n",
       "      <td>35812.277092</td>\n",
       "      <td>46.575236</td>\n",
       "      <td>-47.674618</td>\n",
       "      <td>13.227638</td>\n",
       "      <td>35960.226667</td>\n",
       "      <td>35959.701833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-30 00:02:00</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>35901.60</td>\n",
       "      <td>35921.43</td>\n",
       "      <td>35830.00</td>\n",
       "      <td>35869.61</td>\n",
       "      <td>80.065702</td>\n",
       "      <td>19.83</td>\n",
       "      <td>39.61</td>\n",
       "      <td>31.99</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-23.977043</td>\n",
       "      <td>35990.932415</td>\n",
       "      <td>35815.557585</td>\n",
       "      <td>44.761418</td>\n",
       "      <td>-74.272915</td>\n",
       "      <td>18.875646</td>\n",
       "      <td>35954.054333</td>\n",
       "      <td>35959.528667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-30 00:03:00</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>35867.91</td>\n",
       "      <td>35892.49</td>\n",
       "      <td>35830.00</td>\n",
       "      <td>35861.47</td>\n",
       "      <td>56.834397</td>\n",
       "      <td>24.58</td>\n",
       "      <td>31.47</td>\n",
       "      <td>6.44</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-25.070723</td>\n",
       "      <td>35975.283518</td>\n",
       "      <td>35818.057482</td>\n",
       "      <td>44.307219</td>\n",
       "      <td>-81.920150</td>\n",
       "      <td>18.875646</td>\n",
       "      <td>35946.216000</td>\n",
       "      <td>35958.743000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-30 00:04:00</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>35861.44</td>\n",
       "      <td>35920.29</td>\n",
       "      <td>35844.72</td>\n",
       "      <td>35847.26</td>\n",
       "      <td>41.738493</td>\n",
       "      <td>58.85</td>\n",
       "      <td>2.54</td>\n",
       "      <td>14.18</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-26.775450</td>\n",
       "      <td>35960.503204</td>\n",
       "      <td>35819.385796</td>\n",
       "      <td>43.509915</td>\n",
       "      <td>-70.129566</td>\n",
       "      <td>7.737266</td>\n",
       "      <td>35937.452667</td>\n",
       "      <td>35956.125667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date      tic      open      high       low     close  \\\n",
       "0  2021-06-30 00:00:00  BTCUSDT  35911.72  35941.75  35868.84  35924.04   \n",
       "1  2021-06-30 00:01:00  BTCUSDT  35924.03  35971.25  35850.00  35901.60   \n",
       "2  2021-06-30 00:02:00  BTCUSDT  35901.60  35921.43  35830.00  35869.61   \n",
       "3  2021-06-30 00:03:00  BTCUSDT  35867.91  35892.49  35830.00  35861.47   \n",
       "4  2021-06-30 00:04:00  BTCUSDT  35861.44  35920.29  35844.72  35847.26   \n",
       "\n",
       "      volume  upper_shadow  lower_shadow  real_body  ...  CDLEVENINGSTAR_NEW  \\\n",
       "0  60.951928         17.71         42.88      12.32  ...                   0   \n",
       "1  49.714898         47.22         51.60      22.43  ...                   0   \n",
       "2  80.065702         19.83         39.61      31.99  ...                   0   \n",
       "3  56.834397         24.58         31.47       6.44  ...                   0   \n",
       "4  41.738493         58.85          2.54      14.18  ...                   0   \n",
       "\n",
       "   CDLENGULFINGBEARISH_NEW       macd       boll_ub       boll_lb     rsi_30  \\\n",
       "0                        0 -24.813872  36016.914824  35811.410176  47.891159   \n",
       "1                        0 -23.061153  36008.122908  35812.277092  46.575236   \n",
       "2                        0 -23.977043  35990.932415  35815.557585  44.761418   \n",
       "3                        0 -25.070723  35975.283518  35818.057482  44.307219   \n",
       "4                        0 -26.775450  35960.503204  35819.385796  43.509915   \n",
       "\n",
       "      cci_30      dx_30  close_30_sma  close_60_sma  \n",
       "0 -47.501402  25.261039  35965.887000  35959.781500  \n",
       "1 -47.674618  13.227638  35960.226667  35959.701833  \n",
       "2 -74.272915  18.875646  35954.054333  35959.528667  \n",
       "3 -81.920150  18.875646  35946.216000  35958.743000  \n",
       "4 -70.129566   7.737266  35937.452667  35956.125667  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "eLOnL5eYh1jR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "    model=trained_sac, \n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "ERxw3KqLkcP4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264570, 2)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "2yRkNguY5yvp"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>account_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-06-30 00:00:00</td>\n",
       "      <td>36924.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-30 00:01:00</td>\n",
       "      <td>1000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-30 00:02:00</td>\n",
       "      <td>1000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-30 00:03:00</td>\n",
       "      <td>1000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-30 00:04:00</td>\n",
       "      <td>1000.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date  account_value\n",
       "0  2021-06-30 00:00:00       36924.04\n",
       "1  2021-06-30 00:01:00        1000.00\n",
       "2  2021-06-30 00:02:00        1000.00\n",
       "3  2021-06-30 00:03:00        1000.00\n",
       "4  2021-06-30 00:04:00        1000.00"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2yRkNguY5yvp"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>account_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>264565</th>\n",
       "      <td>2021-12-30 23:55:00</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264566</th>\n",
       "      <td>2021-12-30 23:56:00</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264567</th>\n",
       "      <td>2021-12-30 23:57:00</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264568</th>\n",
       "      <td>2021-12-30 23:58:00</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264569</th>\n",
       "      <td>2021-12-30 23:59:00</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date  account_value\n",
       "264565  2021-12-30 23:55:00         1000.0\n",
       "264566  2021-12-30 23:56:00         1000.0\n",
       "264567  2021-12-30 23:57:00         1000.0\n",
       "264568  2021-12-30 23:58:00         1000.0\n",
       "264569  2021-12-30 23:59:00         1000.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_account_value.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "nFlK5hNbWVFk"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>actions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-06-30 00:00:00</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-30 00:01:00</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-30 00:02:00</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-30 00:03:00</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-30 00:04:00</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date actions\n",
       "0  2021-06-30 00:00:00     [0]\n",
       "1  2021-06-30 00:01:00     [0]\n",
       "2  2021-06-30 00:02:00     [0]\n",
       "3  2021-06-30 00:03:00     [0]\n",
       "4  2021-06-30 00:04:00     [0]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [0]\n",
       "1         [0]\n",
       "2         [0]\n",
       "3         [0]\n",
       "4         [0]\n",
       "         ... \n",
       "264564    [0]\n",
       "264565    [0]\n",
       "264566    [0]\n",
       "264567    [0]\n",
       "264568    [0]\n",
       "Name: actions, Length: 264569, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actions.actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6vvNSC6h1jZ"
   },
   "source": [
    "<a id='6'></a>\n",
    "# Part 7: Backtest Our Strategy\n",
    "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lr2zX7ZxNyFQ"
   },
   "source": [
    "<a id='6.1'></a>\n",
    "## 7.1 BackTestStats\n",
    "pass in df_account_value, this information is stored in env class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "Nzkr9yv-AdV_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n",
      "Annual return         -0.003432\n",
      "Cumulative returns    -0.972917\n",
      "Annual volatility      0.030027\n",
      "Sharpe ratio          -0.030862\n",
      "Calmar ratio          -0.003527\n",
      "Stability              0.000000\n",
      "Max drawdown          -0.972917\n",
      "Omega ratio            0.000000\n",
      "Sortino ratio         -0.030862\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio                  NaN\n",
      "Daily value at risk   -0.003787\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/msc_uol_ai_dissertation/lib/python3.8/site-packages/pyfolio/timeseries.py:724: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  stats = pd.Series()\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/msc_uol_ai_dissertation/lib/python3.8/site-packages/empyrical/stats.py:1527: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.abs(np.percentile(returns, 95)) / \\\n"
     ]
    }
   ],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
    "perf_stats_all.to_csv(\"results/perf_stats_all_\"+now+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QkV-LB66iwhD"
   },
   "outputs": [],
   "source": [
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_df = get_baseline(\n",
    "        ticker=\"^DJI\", \n",
    "        start = df_account_value.loc[0,'date'],\n",
    "        end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
    "\n",
    "stats = backtest_stats(baseline_df, value_col_name = 'close')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qg1kvfemrrQH"
   },
   "outputs": [],
   "source": [
    "df_account_value.loc[0,'date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tt1bzL5OrsTa"
   },
   "outputs": [],
   "source": [
    "df_account_value.loc[len(df_account_value)-1,'date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9U6Suru3h1jc"
   },
   "source": [
    "<a id='6.2'></a>\n",
    "## 7.2 BackTestPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lKRGftSS7pNM"
   },
   "outputs": [],
   "source": [
    "print(\"==============Compare to DJIA===========\")\n",
    "%matplotlib inline\n",
    "# S&P 500: ^GSPC\n",
    "# Dow Jones Index: ^DJI\n",
    "# NASDAQ 100: ^NDX\n",
    "backtest_plot(df_account_value, \n",
    "             baseline_ticker = '^DJI', \n",
    "             baseline_start = df_account_value.loc[0,'date'],\n",
    "             baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BzBaE63H3RLc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZYeOjax-7H_5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Uy5_PTmOh1hj",
    "_gDkU-j-fCmZ",
    "3Zpv4S0-fDBv"
   ],
   "include_colab_link": true,
   "name": "FinRL_StockTrading_NeurIPS_2018.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('msc_uol_ai_dissertation')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "0c0f2ae3d5d9aa27c4a2afc20f28a2482dc1006477ab22953abc78c31c7bb5b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
